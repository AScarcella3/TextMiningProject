{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BOWnotebook.ipynb","provenance":[],"collapsed_sections":["DF6_OdTnXf3W"],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hzolRRT_ANfT"},"source":["# Path e librerie\n","## Prima di modificare avvertire gli altri!"]},{"cell_type":"markdown","metadata":{"id":"NvLbCq-Etlj-"},"source":["## Install"]},{"cell_type":"code","metadata":{"id":"WkMr6gJYuiBg","tags":[],"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637583410494,"user_tz":-60,"elapsed":21823,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"b83918f1-a360-4c89-c0b4-9fea1a3cf8d6"},"source":["#import drive dir\n","from google.colab import drive\n","drive_dir = 'drive' ; \n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"bFQ8FsKNtnrr"},"source":["## Import"]},{"cell_type":"code","metadata":{"id":"W2rdoygctsrH","executionInfo":{"status":"ok","timestamp":1637583412104,"user_tz":-60,"elapsed":9,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}}},"source":["import tweepy\n","import numpy as np\n","from tweepy import Stream, OAuthHandler\n","from tqdm.notebook import tqdm\n","# from tqdm import tqdm !! per Jupyter from tqdm.notebook non funziona, runnare questo\n","import pandas as pd\n","pd.set_option('display.max_colwidth', None) # setta il num. di caratteri visibili per ogni cella della colonna\n","# es. 50 = primi 50 caratteri\n","# None = testo completo\n","\n","import io\n","import pprint\n","import os\n","import glob\n","import warnings\n","warnings.filterwarnings('ignore')\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NTbyaABttqTU","tags":[]},"source":["## Path per Colab"]},{"cell_type":"code","metadata":{"id":"eeZCfUCeuglG","executionInfo":{"status":"ok","timestamp":1637583417141,"user_tz":-60,"elapsed":578,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}}},"source":["##########################\n","### ROOT\n","##########################\n","\n","prj_root_dir = f'/content/{drive_dir}/MyDrive/nucleare/'\n","os.makedirs(prj_root_dir, exist_ok=True)\n","\n","##########################\n","### SCRAPING: file dello scraping di ATP\n","##########################\n","\n","scrapingATP_root_dir = prj_root_dir + 'scrapingATP/'\n","os.makedirs(scrapingATP_root_dir, exist_ok=True)\n","\n","##########################\n","### ETL: \n","##########################\n","\n","etl_root_dir = prj_root_dir + 'ETL/'\n","os.makedirs(etl_root_dir, exist_ok=True)\n","\n","##########################\n","### DWH\n","##########################\n","\n","dw_root_dir = prj_root_dir + 'DWH/'\n","os.makedirs(dw_root_dir, exist_ok=True)\n","\n","##########################\n","### SENTIMENT\n","##########################\n","\n","sentiment_root_dir = prj_root_dir + 'SENTIMENT/'\n","os.makedirs(sentiment_root_dir, exist_ok=True)\n","\n","##########################\n","### WORDEMBEDDING\n","##########################\n","\n","embedding_root_dir = prj_root_dir + 'EMBEDDING/'\n","os.makedirs(embedding_root_dir, exist_ok=True)\n","\n","##########################\n","### OUTPUT\n","##########################\n","\n","output_root_dir = prj_root_dir + 'OUTPUT/'\n","os.makedirs(output_root_dir, exist_ok=True)\n","\n","##########################\n","### STAGING ANTONELLO M.\n","##########################\n","\n","st_man_root_dir = prj_root_dir + 'STAGING_MANENTI/'\n","os.makedirs(st_man_root_dir, exist_ok=True)\n","\n","##########################\n","### STAGING ANTONELLO S.\n","##########################\n","\n","tone_root_dir = prj_root_dir + 'tone/'\n","os.makedirs(tone_root_dir, exist_ok=True)\n","\n","\n","##########################\n","### ML MODELS\n","##########################\n","\n","models_root_dir = prj_root_dir + 'MODELS/'\n","os.makedirs(models_root_dir, exist_ok=True)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"DF6_OdTnXf3W"},"source":["## Path per Jupyter\n","Solo quando si usa Jupyter runnare, il percorso dovrebbe essere lo stesso per tutti/e"]},{"cell_type":"code","metadata":{"id":"5ttVa0GiXf3X"},"source":["##########################\n","### ROOT\n","##########################\n","\n","drive_dir = f'G:\\\\My Drive'\n","prj_root_dir = f'{drive_dir}\\\\nucleare\\\\'\n","\n","##########################\n","### SCRAPING\n","##########################\n","\n","scrapingATP_root_dir = prj_root_dir + 'scrapingATP\\\\'\n","\n","##########################\n","### ETL\n","##########################\n","\n","etl_root_dir = prj_root_dir + 'ETL\\\\'\n","\n","##########################\n","### DWH\n","##########################\n","\n","dw_root_dir = prj_root_dir + 'DWH\\\\'\n","\n","##########################\n","### SENTIMENT\n","##########################\n","\n","sentiment_root_dir = prj_root_dir + 'SENTIMENT\\\\'\n","\n","##########################\n","### WORDEMBEDDING\n","##########################\n","\n","embedding_root_dir = prj_root_dir + 'EMBEDDING\\\\'\n","\n","##########################\n","### OUTPUT\n","##########################\n","\n","output_root_dir = prj_root_dir + 'OUTPUT\\\\'\n","\n","##########################\n","### STAGING ANTONELLO M.\n","##########################\n","\n","st_man_root_dir = prj_root_dir + 'STAGING_MANENTI\\\\'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VVdTk8UXxPkN"},"source":["# 6. BoW\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UfFzJp30Yp6r"},"source":["## 6.1 preprocessing our dataset: lematizzation, stopwords, ngrams"]},{"cell_type":"code","metadata":{"id":"e2oGKuQdxPkT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637583490156,"user_tz":-60,"elapsed":2327,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"07bc48d5-51f8-44d9-b776-ef356272e4d5"},"source":["import nltk ### libreria di linguistica (Stanford)\n","from nltk.stem import WordNetLemmatizer #### individua la radice linguistica delle parole: non tronca le parole come un stamming\n","nltk.download('wordnet') ## tassonomia lingua inglese\n","nltk.download('stopwords')\n","\n","import warnings\n","from tqdm import tqdm\n","from pprint import pprint\n","from gensim.models.phrases import Phrases\n","from nltk.corpus import stopwords\n","pd.set_option('display.max_colwidth', None)\n","\n","connectors = stopwords.words('english')\n","stop = stopwords.words('english')"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","metadata":{"id":"p3rLfDa3ArAt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637583771859,"user_tz":-60,"elapsed":2409,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"dbcce6fd-b82b-4a13-c204-6557038d59a3"},"source":["file_path = output_root_dir +'twitter_text_cleaned_lang_topic_det.csv'\n","df = pd.read_csv(file_path, encoding='utf-8')\n","df['text_cleaned'] = df['text_nonl_hash_men_http_num_simb']\n","print(df.isna().sum())\n","print(df.info())\n","print(df.columns)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["id                                      0\n","user                                    0\n","date                                    0\n","text                                    0\n","favorite_count                          0\n","hashtags                                0\n","location                            33784\n","retweet                                 0\n","retweet_count                           0\n","followers_count                         0\n","in_reply_to_status_id               73270\n","user_mentions                           0\n","date_norm                               0\n","time_zone                               0\n","text_nonl                               0\n","text_nonl_hash                          0\n","text_nonl_hash_men                      0\n","text_nonl_hash_men_http                 0\n","text_nonl_hash_men_http_num             0\n","text_nonl_hash_men_http_num_simb        0\n","Medvedev                                0\n","Zverev                                  0\n","Berrettini                              0\n","Hurkacz                                 0\n","Sinner                                  0\n","Djokovic                                0\n","Tsitsipas                               0\n","Rublev                                  0\n","Ruud                                    0\n","Norrie                                  0\n","ATP_Finals                              0\n","Topic                                   0\n","text_lang                               0\n","text_lan_code                           0\n","lang_confidence                         0\n","prediction_reliable                     0\n","topic                                   0\n","text_cleaned                            0\n","dtype: int64\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 84310 entries, 0 to 84309\n","Data columns (total 38 columns):\n"," #   Column                            Non-Null Count  Dtype  \n","---  ------                            --------------  -----  \n"," 0   id                                84310 non-null  int64  \n"," 1   user                              84310 non-null  object \n"," 2   date                              84310 non-null  object \n"," 3   text                              84310 non-null  object \n"," 4   favorite_count                    84310 non-null  int64  \n"," 5   hashtags                          84310 non-null  object \n"," 6   location                          50526 non-null  object \n"," 7   retweet                           84310 non-null  bool   \n"," 8   retweet_count                     84310 non-null  int64  \n"," 9   followers_count                   84310 non-null  int64  \n"," 10  in_reply_to_status_id             11040 non-null  float64\n"," 11  user_mentions                     84310 non-null  object \n"," 12  date_norm                         84310 non-null  object \n"," 13  time_zone                         84310 non-null  object \n"," 14  text_nonl                         84310 non-null  object \n"," 15  text_nonl_hash                    84310 non-null  object \n"," 16  text_nonl_hash_men                84310 non-null  object \n"," 17  text_nonl_hash_men_http           84310 non-null  object \n"," 18  text_nonl_hash_men_http_num       84310 non-null  object \n"," 19  text_nonl_hash_men_http_num_simb  84310 non-null  object \n"," 20  Medvedev                          84310 non-null  int64  \n"," 21  Zverev                            84310 non-null  int64  \n"," 22  Berrettini                        84310 non-null  int64  \n"," 23  Hurkacz                           84310 non-null  int64  \n"," 24  Sinner                            84310 non-null  int64  \n"," 25  Djokovic                          84310 non-null  int64  \n"," 26  Tsitsipas                         84310 non-null  int64  \n"," 27  Rublev                            84310 non-null  int64  \n"," 28  Ruud                              84310 non-null  int64  \n"," 29  Norrie                            84310 non-null  int64  \n"," 30  ATP_Finals                        84310 non-null  int64  \n"," 31  Topic                             84310 non-null  object \n"," 32  text_lang                         84310 non-null  object \n"," 33  text_lan_code                     84310 non-null  object \n"," 34  lang_confidence                   84310 non-null  float64\n"," 35  prediction_reliable               84310 non-null  bool   \n"," 36  topic                             84310 non-null  object \n"," 37  text_cleaned                      84310 non-null  object \n","dtypes: bool(2), float64(2), int64(15), object(19)\n","memory usage: 23.3+ MB\n","None\n","Index(['id', 'user', 'date', 'text', 'favorite_count', 'hashtags', 'location',\n","       'retweet', 'retweet_count', 'followers_count', 'in_reply_to_status_id',\n","       'user_mentions', 'date_norm', 'time_zone', 'text_nonl',\n","       'text_nonl_hash', 'text_nonl_hash_men', 'text_nonl_hash_men_http',\n","       'text_nonl_hash_men_http_num', 'text_nonl_hash_men_http_num_simb',\n","       'Medvedev', 'Zverev', 'Berrettini', 'Hurkacz', 'Sinner', 'Djokovic',\n","       'Tsitsipas', 'Rublev', 'Ruud', 'Norrie', 'ATP_Finals', 'Topic',\n","       'text_lang', 'text_lan_code', 'lang_confidence', 'prediction_reliable',\n","       'topic', 'text_cleaned'],\n","      dtype='object')\n"]}]},{"cell_type":"code","metadata":{"id":"_pdWM2QkA4hc","colab":{"base_uri":"https://localhost:8080/","height":903},"executionInfo":{"status":"ok","timestamp":1637583777774,"user_tz":-60,"elapsed":189,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"ff06588b-32f4-4a3e-ccf0-370fb3f8a93f"},"source":["df = df[['id', 'user', 'date', 'text', 'text_cleaned','text_lan_code', 'lang_confidence', 'prediction_reliable', 'topic']]\n","print(df.isna().sum())\n","df.info()\n","df.head()"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["id                     0\n","user                   0\n","date                   0\n","text                   0\n","text_cleaned           0\n","text_lan_code          0\n","lang_confidence        0\n","prediction_reliable    0\n","topic                  0\n","dtype: int64\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 84310 entries, 0 to 84309\n","Data columns (total 9 columns):\n"," #   Column               Non-Null Count  Dtype  \n","---  ------               --------------  -----  \n"," 0   id                   84310 non-null  int64  \n"," 1   user                 84310 non-null  object \n"," 2   date                 84310 non-null  object \n"," 3   text                 84310 non-null  object \n"," 4   text_cleaned         84310 non-null  object \n"," 5   text_lan_code        84310 non-null  object \n"," 6   lang_confidence      84310 non-null  float64\n"," 7   prediction_reliable  84310 non-null  bool   \n"," 8   topic                84310 non-null  object \n","dtypes: bool(1), float64(1), int64(1), object(6)\n","memory usage: 5.2+ MB\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>user</th>\n","      <th>date</th>\n","      <th>text</th>\n","      <th>text_cleaned</th>\n","      <th>text_lan_code</th>\n","      <th>lang_confidence</th>\n","      <th>prediction_reliable</th>\n","      <th>topic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1460367104297820165</td>\n","      <td>mandt610</td>\n","      <td>Mon Nov 15 22:00:24 +0000 2021</td>\n","      <td>Rublev‚Äôs revenge üò§\\n\\n@AndreyRublev97 reverses the result from the 2020 #NittoATPFinals and gets the win over Tsitsipas! https://t.co/vQoi9wxPch</td>\n","      <td>Rublev s revenge reverses the result from the and gets the win over Tsitsipas</td>\n","      <td>en</td>\n","      <td>98.0</td>\n","      <td>True</td>\n","      <td>['Rublev' 'Tsitsipas']</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1460367139299282955</td>\n","      <td>LeeFergusson</td>\n","      <td>Mon Nov 15 22:00:32 +0000 2021</td>\n","      <td>Red-hot start üî•\\n\\n@AndreyRublev97 powers past 2019 champion Tsitsipas 6-4 6-4 to get his first win of the 2021 #NittoATPFinals https://t.co/mv9gTC9m0N</td>\n","      <td>Red hot start powers past champion Tsitsipas to get his first win of the</td>\n","      <td>en</td>\n","      <td>98.0</td>\n","      <td>True</td>\n","      <td>['Rublev' 'Tsitsipas']</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1460367219548823556</td>\n","      <td>73Satta</td>\n","      <td>Mon Nov 15 22:00:52 +0000 2021</td>\n","      <td>Alexander Zverev #NittoATPFinals https://t.co/NN9iNnheHA</td>\n","      <td>Alexander Zverev</td>\n","      <td>sk</td>\n","      <td>94.0</td>\n","      <td>False</td>\n","      <td>['Zverev']</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1460367236573638665</td>\n","      <td>bikson82</td>\n","      <td>Mon Nov 15 22:00:56 +0000 2021</td>\n","      <td>When the üê∫ met the ü¶Å\\n\\n@DjokerNole ü§ù @Ibra_official \\n\\n#NittoATPFinals https://t.co/za2aB5HnIJ</td>\n","      <td>When the met the</td>\n","      <td>en</td>\n","      <td>94.0</td>\n","      <td>True</td>\n","      <td>['Djokovic']</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1460367240960917507</td>\n","      <td>BarthelSamantha</td>\n","      <td>Mon Nov 15 22:00:57 +0000 2021</td>\n","      <td>üíôü§çüíôü§çüá¨üá∑ #Tsitsipas #NittoATPFinals https://t.co/8gFUvYyqiU</td>\n","      <td></td>\n","      <td>un</td>\n","      <td>0.0</td>\n","      <td>False</td>\n","      <td>['Tsitsipas']</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    id  ...                   topic\n","0  1460367104297820165  ...  ['Rublev' 'Tsitsipas']\n","1  1460367139299282955  ...  ['Rublev' 'Tsitsipas']\n","2  1460367219548823556  ...              ['Zverev']\n","3  1460367236573638665  ...            ['Djokovic']\n","4  1460367240960917507  ...           ['Tsitsipas']\n","\n","[5 rows x 9 columns]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"QtkYQ0dK6lhp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637583849658,"user_tz":-60,"elapsed":190,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"f31ccf6a-4951-4333-ed7e-dd53979522ff"},"source":["print(f'original len: {len(df)}')\n","\n","dff = df[df['text_lan_code'].isin(['en'])]\n","eng_len = len(dff)\n","print(f'english len: {eng_len}')\n","\n","dff = dff[dff['prediction_reliable'] == True]\n","dff = dff[dff['lang_confidence'] > 96]\n","\n","print(f'filtered len: {len(dff)}')\n","print(f'loss: {eng_len - len(dff)}')\n","\n","print(dff.isna().sum())\n","print(dff.groupby(['text_lan_code', 'prediction_reliable']).size())\n","print(dff.groupby(['text_lan_code', 'lang_confidence']).size())"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["original len: 84310\n","english len: 49252\n","filtered len: 36557\n","loss: 12695\n","id                     0\n","user                   0\n","date                   0\n","text                   0\n","text_cleaned           0\n","text_lan_code          0\n","lang_confidence        0\n","prediction_reliable    0\n","topic                  0\n","dtype: int64\n","text_lan_code  prediction_reliable\n","en             True                   36557\n","dtype: int64\n","text_lan_code  lang_confidence\n","en             97.0                5329\n","               98.0               16647\n","               99.0               14581\n","dtype: int64\n"]}]},{"cell_type":"code","metadata":{"id":"L5Ykdc_uxPkU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637587251838,"user_tz":-60,"elapsed":3775,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"a4e259de-63af-492d-885d-6878e46aced1"},"source":["df = dff.copy()\n","\n","lemmatizer = WordNetLemmatizer()\n","df['text_cleaned'] = df['text_cleaned'].str.lower().str.replace('[^\\w\\s\\d]',' ', regex=True) #type(text) series of string\n","df['text_cleaned'] = df['text_cleaned'].str.lower().str.replace('\\s+', ' ', regex=True) ## rimuovi spazi multipli\n","\n","raw_text = df[~df['text_cleaned'].isna()]['text_cleaned']\n","\n","print(len(raw_text))\n","\n","####pulizia: sostituisco tutti i caratteri speciali con uno spazio\n","text = raw_text.str.lower()\n","print(len(text))\n","print(text.head())\n","\n","###TOKENIZATION\n","df['token'] = text.str.split() ##text: series of list, text[0] list of string, text[0][0] string \n","\n","###LEMMATIZATION\n","df['ltoken'] = df.token.apply(lambda x: [lemmatizer.lemmatize(sent) for sent in x]) #text: series of list, text[0] list of string (lemmatized), text[0][0] string\n","\n","# print(f'text[0][0]-({type(df.ltoken[0][0])})')\n","# print(f'text[0]-({type(df.ltoken[0])})')\n","# print(f'text-({type(df.ltoken)})')\n","\n","print(f'text_cleaned: {df.text_cleaned[0]}')\n","print(f'token       : {df.token[0]}')\n","print(f'ltoken      : {df.ltoken[0]}')\n","\n","# stop.extend(['good', 'bad', 'dont', 'many', 'love', 'excellent', 'would', 'perfect', 'even', 'great','nice', 'amazing'])\n"],"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["36557\n","36557\n","0                 rublev s revenge reverses the result from the and gets the win over tsitsipas \n","1                      red hot start powers past champion tsitsipas to get his first win of the \n","5                      red hot start powers past champion tsitsipas to get his first win of the \n","6                 rublev s revenge reverses the result from the and gets the win over tsitsipas \n","7    milan turin three years after their next gen semi final meeting amp battled again in italy \n","Name: text_cleaned, dtype: object\n","text_cleaned: rublev s revenge reverses the result from the and gets the win over tsitsipas \n","token       : ['rublev', 's', 'revenge', 'reverses', 'the', 'result', 'from', 'the', 'and', 'gets', 'the', 'win', 'over', 'tsitsipas']\n","ltoken      : ['rublev', 's', 'revenge', 'revers', 'the', 'result', 'from', 'the', 'and', 'get', 'the', 'win', 'over', 'tsitsipas']\n"]}]},{"cell_type":"code","metadata":{"id":"ix4tTrNEFTt2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637587258970,"user_tz":-60,"elapsed":214,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"2523333c-aba4-4097-a0c4-239a3f0931ea"},"source":["number = 1\n","print(f'text_cleaned: {df.text_cleaned.to_list()[number]}')\n","print(f'token       : {df.token.to_list()[number]}')\n","print(f'ltoken      : {df.ltoken.to_list()[number]}')"],"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["text_cleaned: red hot start powers past champion tsitsipas to get his first win of the \n","token       : ['red', 'hot', 'start', 'powers', 'past', 'champion', 'tsitsipas', 'to', 'get', 'his', 'first', 'win', 'of', 'the']\n","ltoken      : ['red', 'hot', 'start', 'power', 'past', 'champion', 'tsitsipas', 'to', 'get', 'his', 'first', 'win', 'of', 'the']\n"]}]},{"cell_type":"code","metadata":{"id":"UCRsvA9eFynK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637587263192,"user_tz":-60,"elapsed":185,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"8a81e4d6-efb6-45ab-97a6-9edbaa09847e"},"source":["print(df.isna().sum())\n","len_target = 1\n","field_name ='token' \n","counter = df[df[field_name].str.len() < len_target ][field_name].count()\n","print(f'{field_name} with len < {len_target}: {counter}')"],"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["id                     0\n","user                   0\n","date                   0\n","text                   0\n","text_cleaned           0\n","text_lan_code          0\n","lang_confidence        0\n","prediction_reliable    0\n","topic                  0\n","token                  0\n","ltoken                 0\n","dtype: int64\n","token with len < 1: 0\n"]}]},{"cell_type":"code","metadata":{"id":"kuWZ87umDwBy","executionInfo":{"status":"ok","timestamp":1637587282963,"user_tz":-60,"elapsed":17026,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}}},"source":["my_stop_words = []\n","stop.extend(my_stop_words)\n","\n","df['ltoken'] = df.ltoken.apply(lambda row: [item for item in row if item not in my_stop_words])\n","\n","df['stopwords'] = df.ltoken.apply(lambda row: [item for item in row if item in stop])\n","df['nostopwords'] = df.ltoken.apply(lambda row: [item for item in row if item not in stop])\n","\n","bigram  = Phrases(df.ltoken, min_count=5, threshold=0.2, common_terms=connectors) #gensim 3, ad esempio \"and\" \n","df['bigrams_afternostop'] = df.ltoken.apply(lambda row: bigram[row])\n","\n","ngram   = Phrases(df.bigrams_afternostop, min_count=5, threshold=0.2, common_terms=connectors) # gensim 3\n","df['ngrams_afternostop'] = df.bigrams_afternostop.apply(lambda row: ngram[row])\n","\n","df.bigrams_afternostop = df.bigrams_afternostop.apply(lambda bigr: [item for item in bigr if item not in stop])\n","df.ngrams_afternostop = df.ngrams_afternostop.apply(lambda ngr: [item for item in ngr if item not in stop])\n","\n","bigram  = Phrases(df.nostopwords, min_count=5, threshold=0.2, common_terms=connectors) #gensim 3, ad esempio \"and\" \n","df['bigrams_beforenostop'] = df.nostopwords.apply(lambda row: bigram[row])\n","\n","ngram   = Phrases(df.bigrams_beforenostop, min_count=5, threshold=0.2, common_terms=connectors) # gensim 3\n","df['ngrams_beforenostop'] = df.bigrams_beforenostop.apply(lambda row: ngram[row])\n","\n","df['bigrams_afternostop_sent'] = df.bigrams_afternostop.apply(lambda row: ' '.join(row))\n","df['bigrams_beforenostop_sent'] = df.bigrams_beforenostop.apply(lambda row: ' '.join(row))\n","df['ngrams_afternostop_sent'] = df.ngrams_afternostop.apply(lambda row: ' '.join(row))\n","df['ngrams_beforenostop_sent'] = df.ngrams_beforenostop.apply(lambda row: ' '.join(row))"],"execution_count":86,"outputs":[]},{"cell_type":"code","metadata":{"id":"5xTAXVZfIJ6W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637583989961,"user_tz":-60,"elapsed":181,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"d7abdf09-d3e6-4a4b-e051-b53b99284f7c"},"source":["# print(df.isna().sum())\n","len_target = 1\n","# 'bigrams_afternostop_sent' \n","# 'bigrams_beforenostop_sent'\n","# 'ngrams_afternostop_sent'  \n","# 'ngrams_beforenostop_sent' \n","field_name ='ngrams_beforenostop_sent' \n","counter = df[df[field_name].str.len() < len_target ][field_name].count()\n","print(f'{field_name} with len < {len_target}: {counter}')\n","\n","n = 10\n","print(f'df.bigrams_afternostop_sent[{n}] : {df.bigrams_afternostop_sent.to_list()[n]}')\n","print(f'df.bigrams_beforenostop_sent[{n}]: {df.bigrams_beforenostop_sent.to_list()[n]}')\n","print(f'df.ngrams_afternostop_sent[{n}]  : {df.ngrams_afternostop_sent.to_list()[n]}')\n","print(f'df.ngrams_beforenostop_sent[{n}] : {df.ngrams_beforenostop_sent.to_list()[n]}')"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["ngrams_beforenostop_sent with len < 1: 0\n","df.bigrams_afternostop_sent[10] : bravissimo_wa awarded_the_year end_atp tour_no_trophy presented_by_following win_over_casper ruud\n","df.bigrams_beforenostop_sent[10]: bravissimo_wa awarded_year end_atp tour_trophy presented_following win_casper ruud\n","df.ngrams_afternostop_sent[10]  : bravissimo_wa_awarded_the_year end_atp_tour_no_trophy presented_by_following_his_win_over_casper ruud\n","df.ngrams_beforenostop_sent[10] : bravissimo_wa_awarded_year end_atp_tour_trophy presented_following_win_casper ruud\n"]}]},{"cell_type":"code","metadata":{"id":"O6DbE5TmJG0N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1b94e4a3-59a8-4e73-9924-5ea3a4877c2b"},"source":["df.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['id', 'user', 'date', 'text_cleaned', 'text_lang', 'text_lan_code',\n","       'lang_confidence', 'prediction_reliable', 'token', 'ltoken',\n","       'stopwords', 'nostopwords', 'bigrams_afternostop', 'ngrams_afternostop',\n","       'bigrams_beforenostop', 'ngrams_beforenostop',\n","       'bigrams_afternostop_sent', 'bigrams_beforenostop_sent',\n","       'ngrams_afternostop_sent', 'ngrams_beforenostop_sent'],\n","      dtype='object')"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"tznsaSoSrrWi"},"source":["### 6.1.1 Saving"]},{"cell_type":"code","metadata":{"id":"GYE_PmU-rxVD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637587288850,"user_tz":-60,"elapsed":1137,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"a0ca0751-a59d-4cbc-cf02-ef9cf64ef1b4"},"source":["df_saving = df.copy() #.replace('\\n','', regex=True)\n","df_saving = df_saving[['id', 'user', 'date', 'text', 'text_cleaned','text_lan_code', 'lang_confidence', 'prediction_reliable', 'topic',\n","       'bigrams_afternostop_sent', 'bigrams_beforenostop_sent',\n","       'ngrams_afternostop_sent', 'ngrams_beforenostop_sent']]\n","saving_file_name = f'{sentiment_root_dir}ngrams_ourdataset_dataframe.csv'\n","df_saving.to_csv(saving_file_name, index=False, encoding='utf-8', sep =',' )\n","df_saving.isna().sum()"],"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id                           0\n","user                         0\n","date                         0\n","text                         0\n","text_cleaned                 0\n","text_lan_code                0\n","lang_confidence              0\n","prediction_reliable          0\n","topic                        0\n","bigrams_afternostop_sent     0\n","bigrams_beforenostop_sent    0\n","ngrams_afternostop_sent      0\n","ngrams_beforenostop_sent     0\n","dtype: int64"]},"metadata":{},"execution_count":87}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-IKvGy2nzVZ","executionInfo":{"status":"ok","timestamp":1637587293362,"user_tz":-60,"elapsed":782,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"3b4df33a-214c-4bdf-dfcc-70c269baf09b"},"source":["opening_file_name = f'{sentiment_root_dir}ngrams_ourdataset_dataframe.csv'\n","df_open = pd.read_csv(opening_file_name, encoding='utf-8', sep =',' )\n","df_open.isna().sum()"],"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id                           0\n","user                         0\n","date                         0\n","text                         0\n","text_cleaned                 0\n","text_lan_code                0\n","lang_confidence              0\n","prediction_reliable          0\n","topic                        0\n","bigrams_afternostop_sent     0\n","bigrams_beforenostop_sent    0\n","ngrams_afternostop_sent      0\n","ngrams_beforenostop_sent     0\n","dtype: int64"]},"metadata":{},"execution_count":88}]},{"cell_type":"markdown","metadata":{"id":"bzXO8V4FoZOG"},"source":["## 6.2 Fit dictionary and save it"]},{"cell_type":"code","metadata":{"id":"9Vr0RCYjoYOf","executionInfo":{"status":"ok","timestamp":1637587614398,"user_tz":-60,"elapsed":6856,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}}},"source":["import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","import pickle\n","\n","    \n","df = df_open.copy()\n","\n","choosen_column_2vec = 'ngrams_afternostop_sent'\n","\n","vectorizer = CountVectorizer(ngram_range=(1, 1), max_features=1000)\n","# vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=1000)\n","X = vectorizer.fit_transform(df['ngrams_afternostop_sent'].to_list())\n","feature_names = vectorizer.get_feature_names()\n","# print(feature_names)\n","\n","model_filename = f\"{models_root_dir}our_bow_dict_model.pkl\"\n","with open(model_filename, 'wb') as file:\n","    pickle.dump(vectorizer, file)\n"],"execution_count":95,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P0dA7aIspDMN","executionInfo":{"status":"ok","timestamp":1637587628187,"user_tz":-60,"elapsed":187,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"57607762-eaa6-4762-9d42-2327c91c9dc9"},"source":["print(X)\n","print(feature_names[0:100])"],"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["  (0, 652)\t1\n","  (0, 89)\t1\n","  (0, 699)\t1\n","  (1, 825)\t1\n","  (1, 735)\t1\n","  (1, 165)\t1\n","  (2, 825)\t1\n","  (2, 636)\t1\n","  (2, 398)\t1\n","  (2, 566)\t1\n","  (2, 575)\t1\n","  (2, 866)\t1\n","  (2, 957)\t1\n","  (2, 581)\t1\n","  (2, 59)\t1\n","  (2, 520)\t1\n","  (2, 840)\t1\n","  (2, 455)\t1\n","  (2, 915)\t1\n","  (2, 234)\t2\n","  (2, 829)\t1\n","  (2, 979)\t1\n","  (2, 831)\t1\n","  (2, 497)\t1\n","  (2, 382)\t1\n","  :\t:\n","  (223900, 602)\t1\n","  (223900, 124)\t1\n","  (223900, 113)\t1\n","  (223900, 722)\t1\n","  (223901, 312)\t1\n","  (223901, 591)\t2\n","  (223901, 419)\t1\n","  (223901, 602)\t1\n","  (223901, 406)\t1\n","  (223901, 953)\t1\n","  (223901, 544)\t1\n","  (223902, 208)\t1\n","  (223902, 106)\t1\n","  (223902, 971)\t1\n","  (223903, 575)\t1\n","  (223903, 543)\t1\n","  (223903, 219)\t1\n","  (223904, 348)\t1\n","  (223904, 931)\t2\n","  (223904, 210)\t1\n","  (223904, 770)\t1\n","  (223904, 345)\t1\n","  (223904, 769)\t1\n","  (223904, 308)\t1\n","  (223904, 651)\t1\n","['00', '000', '10', '100', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '200', '2019', '2020', '24', '25', '2_day', '2_week', '30', '3_day', '3_week', '40', '50', '60', '99', '_great', '_however', '_i', '_i_called', '_i_wa', '_i_would', '_thank', '_thanks', 'able', 'absolutely', 'access', 'account', 'accurate', 'actual', 'actually', 'ad', 'add', 'added', 'additional', 'address', 'advertised', 'advice', 'affordable', 'again', 'agent', 'ago', 'all', 'allow', 'almost', 'along', 'already', 'also', 'although', 'always', 'amazing', 'amazon', 'amount', 'and', 'another', 'answer', 'answered', 'anymore', 'anyone', 'anything', 'anyway', 'app', 'apparently', 'application', 'appointment', 'appreciate', 'april', 'area', 'around', 'arrive', 'arrived', 'ask', 'asked', 'asking', 'available', 'avoid', 'away', 'awesome', 'awful', 'back', 'bad', 'bag', 'bank', 'based', 'basically', 'beautiful', 'before', 'beginning']\n"]}]},{"cell_type":"markdown","metadata":{"id":"O5CCk-khY2az"},"source":["## 6.2 Preprocesing Trustpilot dataset"]},{"cell_type":"code","metadata":{"id":"56OEm9zl3ZDq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637584690286,"user_tz":-60,"elapsed":7117,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"d9f50ef1-196a-4b09-e0bf-05b05e51e01c"},"source":["pd.set_option('display.max_colwidth', None)\n","file_path = tone_root_dir +'trustpilot_review_for_ML.csv'\n","df_open = pd.read_csv(file_path)\n","len(df_open)"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1652277"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"ogYd7hK94JmL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637584740349,"user_tz":-60,"elapsed":5430,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"32c08432-5972-45f2-dab6-da8a66693e0e"},"source":["dftp = df_open.copy()\n","\n","dftp = dftp[dftp.rating != 'rating']\n","dftp = dftp[~dftp.rating.isin([3,'3', 'rating'])]\n","dftp = dftp.drop_duplicates()\n","dftp.rating = dftp.rating.astype('int') \n","print(len(dftp))\n","print(dftp.groupby(['rating']).size().index)\n","print(dftp.groupby(['rating']).size())\n","\n","df1 = dftp[dftp.rating == 1 ]\n","df2 = dftp[dftp.rating == 2 ]\n","df4 = dftp[dftp.rating == 4 ]\n","df5 = dftp[dftp.rating == 5 ]\n","\n","df4 = df4.sample(len(df2), random_state= 123)\n","df5 = df5.sample(len(df1), random_state= 123)\n","print(f'df1: {len(df1)}')\n","print(f'df2: {len(df2)}')\n","print(f'df4: {len(df4)}')\n","print(f'df5: {len(df5)}')\n","\n","dftp = df1.copy()\n","dftp = dftp.append(df2)\n","dftp = dftp.append(df4)\n","dftp = dftp.append(df5)\n","print(dftp.groupby(['rating']).size())\n","print(dftp.groupby(['rating']).size())\n","print(len(dftp))\n","\n","dftp.to_csv(tone_root_dir +'balanced_trustpilot_review_for_ML.csv', index=False, encoding='utf-8')"],"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["1012482\n","Int64Index([1, 2, 4, 5], dtype='int64', name='rating')\n","rating\n","1     88110\n","2     23884\n","4     86730\n","5    813758\n","dtype: int64\n","df1: 88110\n","df2: 23884\n","df4: 23884\n","df5: 88110\n","rating\n","1    88110\n","2    23884\n","4    23884\n","5    88110\n","dtype: int64\n","rating\n","1    88110\n","2    23884\n","4    23884\n","5    88110\n","dtype: int64\n","223988\n"]}]},{"cell_type":"code","metadata":{"id":"0cr3ull-8RJz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637584747581,"user_tz":-60,"elapsed":1479,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"60e0cd96-6200-48d4-c132-bb8aa9a8cecf"},"source":["df_open = pd.read_csv(tone_root_dir +'balanced_trustpilot_review_for_ML.csv', encoding='utf-8')\n","print(df_open.groupby(['rating']).size())\n","print(len(df_open))\n","df_open.rating.value_counts()"],"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["rating\n","1    88110\n","2    23884\n","4    23884\n","5    88110\n","dtype: int64\n","223988\n"]},{"output_type":"execute_result","data":{"text/plain":["5    88110\n","1    88110\n","4    23884\n","2    23884\n","Name: rating, dtype: int64"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"PNsRBIo96ZKK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637585777265,"user_tz":-60,"elapsed":2292,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"9c9fc424-17b7-46ee-c8ef-a586043ed460"},"source":["df = df_open.copy()\n","print(df.isna().sum())\n","df.rating.value_counts()\n","\n","def binary(row):\n","    if row['rating'] > 3:\n","        val = 1\n","    else:\n","        val = 0\n","    return val\n","\n","df['y'] = df.apply(binary, axis=1) ### axis = 1 --> sulle righe\n","print(len(df))\n","#escludo dal dataset le review null e le review neutre \n","df = df[~(df['comment'].isna())]\n","print(len(df))\n","#recupero dal dataset i testi delle reviews (X)\n","raw_text = df['comment']\n","\n","print(raw_text[1])\n","#recupero la lista dei binary weight (y)\n","y = df['y'].tolist()\n"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["comment    0\n","rating     0\n","dtype: int64\n","223988\n","223988\n","This product is awesome! Super helpful with the nerve damage sustained from a dog bit incident. Couldnt recommended a better product\n"]}]},{"cell_type":"code","metadata":{"id":"5nPxvMUMBie1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637586291155,"user_tz":-60,"elapsed":63674,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"c9bdb5cf-61f5-4ef9-a0d4-27bc4c76fff9"},"source":["import nltk ### libreria di linguistica (Stanford)\n","nltk.download('wordnet') ## tassonomia lingua inglese\n","\n","from tqdm import tqdm\n","from nltk.stem import WordNetLemmatizer #### individua la radice linguistica delle parole: non tronca le parole come un stamming\n","lemmatizer = WordNetLemmatizer()\n","\n","raw_text = df[~df['comment'].isna()].loc[:, 'comment']\n","print(len(raw_text))\n","\n","####pulizia: sostituisco tutti i caratteri speciali con uno spazio\n","text = raw_text.str.lower().str.replace('[^\\w\\s\\d]',' ', regex=True) #type(text) series of string\n","text = text.str.lower().str.replace('\\s+', ' ', regex=True) ## rimuovi spazi multipli\n","# text = raw_text.str.replace('!\"%&()?^,.-;:_', ' ', regex=False) ## rimuovi spazi multipli\n","print(len(text))\n","\n","# ##TOKENIZATION\n","df['token'] = text.str.split() ##text: series of list, text[0] list of string, text[0][0] string\n","print(df['token'].head(1000))\n","\n","print(f\"\"\"df before filter \n","{len(df)}\"\"\") \n","print(df.isna().sum())\n","print(f\"\"\"df after filter \n","{len(df)}\"\"\") \n","\n","# ###LEMMATIZATION\n","df['ltoken'] = df.token.apply(lambda x: [lemmatizer.lemmatize(sent) for sent in x]) #text: series of list, text[0] list of string (lemmatized), text[0][0] string\n","\n","print(f'text[0][0]-({type(df.token[0][0])})')\n","print(f'text[0]-({type(df.token[0])})')\n","print(f'text-({type(df.token)})')\n","print(f'text[0][0]-({(df.token[0][0])})')\n","print(f'text[0]-({(df.token[0])})')\n","print(f'text-({(df.token)})')\n"],"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","223988\n","223988\n","0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [tttsfddfhfdhdhdhdhf]\n","1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [this, product, is, awesome, super, helpful, with, the, nerve, damage, sustained, from, a, dog, bit, incident, couldnt, recommended, a, better, product]\n","2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [super, safe, helmet, and, very, comfortable]\n","3                                                          [i, am, pretty, frustrated, with, him, my, boyfriend, decided, to, buy, me, one, of, the, buffalo, bags, he, ordered, it, back, in, october, and, the, at, the, time, the, website, stated, 3, 4, to, weeks, and, it, would, be, sent, out, he, also, accepted, the, money, we, have, tried, and, tried, to, talk, to, him, and, he, ignores, messages, he, messaged, back, once, 11, weeks, later, and, he, is, still, ignoring, us, very, very, disappointed, i, would, love, to, support, his, work, as, it, a, gorgeous, but, he, is, sure, it, making, it, hard, he, could, at, least, message, back, ...]\n","4                                                                                                                                                                                                                                                                                                                                            [stealing, my, money, ordered, a, coat, and, returned, it, still, waiting, for, refund, 45, days, later, they, have, n, o, excuse, except, to, blame, it, on, my, bank, which, is, not, correct, as, i, work, in, the, pos, industry, as, of, now, they, have, stolen, from, me, and, they, do, not, care, at, all, horrible]\n","                                                                                                                                                                                                                                                                                                                                      ...                                                                                                                                                                                                                                                                                                                                 \n","995                                      [if, i, could, put, 0, stars, i, absolutely, would, simply, for, the, fact, that, the, customer, service, is, horrible, i, tried, to, order, one, container, of, itch, chews, for, my, dogs, just, to, try, after, i, put, my, card, information, in, i, was, immediately, charged, for, another, container, and, a, container, of, joint, chews, as, well, i, immediately, tried, to, cancel, the, order, which, was, not, even, an, option, so, i, emailed, them, had, to, create, a, ticket, just, to, send, the, email, and, then, waited, for, a, reply, and, did, not, get, an, answer, today, i, received, an, email, ...]\n","996                                    [i, purchased, the, chews, on, the, 5th, july, have, received, nothing, can, see, payment, on, my, paypal, account, 33, 95, but, cannot, find, any, order, information, on, my, emails, so, cant, send, email, as, i, cant, retrieve, any, order, number, so, how, do, i, chase, it, up, or, get, a, refund, for, something, i, didnt, receive, meanwhile, my, poor, dog, is, still, itching, really, badly, update, what, a, surprise, i, send, an, email, to, the, account, given, with, a, picture, of, my, payment, taken, through, paypal, and, it, is, unable, to, deliver, i, will, make, sure, i, warn, other, people, ...]\n","997                                                                                                                                                                                                    [do, not, i, repeat, do, not, buy, anything, from, this, company, the, products, total, rip, off, they, charge, your, card, without, even, permission, and, the, 90, day, money, back, is, total, bs, i, have, been, back, in, fourth, for, two, weeks, trying, to, get, a, refund, they, stole, from, me, now, im, having, to, go, threw, bank, cause, there, making, excuse, like, its, my, fault, if, i, could, drop, a, bomp, it, would, be, on, this, company]\n","998    [i, ordered, two, seperate, orders, and, two, weeks, later, they, have, notl, been, delivered, when, i, emailed, them, i, was, told, the, order, was, held, up, five, days, because, their, system, believed, the, orders, were, fraudulent, however, both, paypal, and, the, backing, credit, card, had, been, billed, on, the, very, day, order, was, placed, two, emails, to, the, business, had, me, assuming, responsibility, for, this, and, all, 5hey, could, do, for, me, was, offer, me, a, refund, if, i, shipped, the, items, back, when, they, finally, arrived, their, prices, are, on, the, high, side, and, their, shipping, and, handling, is, ...]\n","999                                                                                                                                   [absolutely, terrible, customer, service, i, placed, an, order, through, amazon, and, after, almost, a, month, i, received, a, wrong, order, when, i, filed, a, return, request, the, representative, insisted, that, i, received, the, correct, order, which, was, a, blatant, lie, now, i, am, trying, to, reach, them, but, no, one, is, picking, up, their, phone, and, the, representative, has, not, replied, to, my, email, after, 2, days, one, of, the, worst, examples, of, customer, service, i, have, ever, encountered]\n","Name: token, Length: 1000, dtype: object\n","df before filter \n","223988\n","comment    0\n","rating     0\n","y          0\n","token      0\n","dtype: int64\n","df after filter \n","223988\n","text[0][0]-(<class 'str'>)\n","text[0]-(<class 'list'>)\n","text-(<class 'pandas.core.series.Series'>)\n","text[0][0]-(tttsfddfhfdhdhdhdhf)\n","text[0]-(['tttsfddfhfdhdhdhdhf'])\n","text-(0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [tttsfddfhfdhdhdhdhf]\n","1                                                                                                                                                                                                                                                                                                                                                                                                                                                                [this, product, is, awesome, super, helpful, with, the, nerve, damage, sustained, from, a, dog, bit, incident, couldnt, recommended, a, better, product]\n","2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [super, safe, helmet, and, very, comfortable]\n","3         [i, am, pretty, frustrated, with, him, my, boyfriend, decided, to, buy, me, one, of, the, buffalo, bags, he, ordered, it, back, in, october, and, the, at, the, time, the, website, stated, 3, 4, to, weeks, and, it, would, be, sent, out, he, also, accepted, the, money, we, have, tried, and, tried, to, talk, to, him, and, he, ignores, messages, he, messaged, back, once, 11, weeks, later, and, he, is, still, ignoring, us, very, very, disappointed, i, would, love, to, support, his, work, as, it, a, gorgeous, but, he, is, sure, it, making, it, hard, he, could, at, least, message, back, ...]\n","4                                                                                                                                                                                                                                                                                           [stealing, my, money, ordered, a, coat, and, returned, it, still, waiting, for, refund, 45, days, later, they, have, n, o, excuse, except, to, blame, it, on, my, bank, which, is, not, correct, as, i, work, in, the, pos, industry, as, of, now, they, have, stolen, from, me, and, they, do, not, care, at, all, horrible]\n","                                                                                                                                                                                                                                                                                                               ...                                                                                                                                                                                                                                                                                                       \n","223983                                                                                                                                                                                                                                                                                                                                                                                      [i, really, like, the, quality, and, results, these, products, from, bot, i, have, called, for, information, bought, equine, and, people, products, and, never, been, disappointed, at, the, quality, and, customer, service]\n","223984                                                                                                                                                                                                                                                                                        [these, shoes, are, extremely, comfortable, i, have, many, problems, with, my, feet, including, arthritis, hammer, toe, and, bunions, and, can, wear, these, shoes, for, hours, with, no, pain, i, recommend, them, highly, to, people, with, foot, pain, you, will, feel, like, you, are, walking, on, a, cloud, so, nice]\n","223985                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [absolutely, perfect, pretty, polite, is, so, easy, to, work, with, they, truly, care, about, your, big, day]\n","223986                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [next, day, delivered, service, is, excellent, just, what, i, ordered]\n","223987                                                                                                                                                                              [i, ordered, 8, days, ago, but, the, order, status, still, shows, processing, even, though, it, was, been, shipped, and, i, have, received, it, it, was, the, the, day, after, i, ordered, before, it, was, shipped, and, i, had, to, call, to, find, out, when, it, was, shipping, it, was, shipped, by, fedex, and, did, get, to, me, in, a, few, days, just, don, t, count, on, the, order, status, to, give, useful, information]\n","Name: token, Length: 223988, dtype: object)\n"]}]},{"cell_type":"code","metadata":{"id":"llZq_AUED78d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637586291473,"user_tz":-60,"elapsed":358,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"ae67f7dc-22bb-48d4-e320-8986fd51beed"},"source":["number = 3\n","print(f'comment     : {df.comment.to_list()[number]}')\n","print(f'token       : {df.token.to_list()[number]}')\n","print(f'ltoken      : {df.ltoken.to_list()[number]}')\n","\n","print(df.isna().sum())\n","\n","len_target = 1\n","field_name ='ltoken' \n","counter = df[df[field_name].str.len() < len_target ][field_name].count()\n","print(f'{field_name} with len < {len_target}: {counter}')\n","\n"],"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["comment     : I am pretty frustrated with him! My boyfriend decided to buy me one of the buffalo bags! He ordered it back in October and the at the time the website stated 3-4 to weeks and it would be sent out! He also accepted the money! We have tried and tried to talk to him and he ignores messages, he messaged back once! 11 weeks later and he is still ignoring us! Very very disappointed! I would love to support his work as it a gorgeous but he is sure it making it hard! He could at least message back... saying anything, possibly a hey I am super busy and I would be happy and understanding. Very disappointed!!!\n","token       : ['i', 'am', 'pretty', 'frustrated', 'with', 'him', 'my', 'boyfriend', 'decided', 'to', 'buy', 'me', 'one', 'of', 'the', 'buffalo', 'bags', 'he', 'ordered', 'it', 'back', 'in', 'october', 'and', 'the', 'at', 'the', 'time', 'the', 'website', 'stated', '3', '4', 'to', 'weeks', 'and', 'it', 'would', 'be', 'sent', 'out', 'he', 'also', 'accepted', 'the', 'money', 'we', 'have', 'tried', 'and', 'tried', 'to', 'talk', 'to', 'him', 'and', 'he', 'ignores', 'messages', 'he', 'messaged', 'back', 'once', '11', 'weeks', 'later', 'and', 'he', 'is', 'still', 'ignoring', 'us', 'very', 'very', 'disappointed', 'i', 'would', 'love', 'to', 'support', 'his', 'work', 'as', 'it', 'a', 'gorgeous', 'but', 'he', 'is', 'sure', 'it', 'making', 'it', 'hard', 'he', 'could', 'at', 'least', 'message', 'back', 'saying', 'anything', 'possibly', 'a', 'hey', 'i', 'am', 'super', 'busy', 'and', 'i', 'would', 'be', 'happy', 'and', 'understanding', 'very', 'disappointed']\n","ltoken      : ['i', 'am', 'pretty', 'frustrated', 'with', 'him', 'my', 'boyfriend', 'decided', 'to', 'buy', 'me', 'one', 'of', 'the', 'buffalo', 'bag', 'he', 'ordered', 'it', 'back', 'in', 'october', 'and', 'the', 'at', 'the', 'time', 'the', 'website', 'stated', '3', '4', 'to', 'week', 'and', 'it', 'would', 'be', 'sent', 'out', 'he', 'also', 'accepted', 'the', 'money', 'we', 'have', 'tried', 'and', 'tried', 'to', 'talk', 'to', 'him', 'and', 'he', 'ignores', 'message', 'he', 'messaged', 'back', 'once', '11', 'week', 'later', 'and', 'he', 'is', 'still', 'ignoring', 'u', 'very', 'very', 'disappointed', 'i', 'would', 'love', 'to', 'support', 'his', 'work', 'a', 'it', 'a', 'gorgeous', 'but', 'he', 'is', 'sure', 'it', 'making', 'it', 'hard', 'he', 'could', 'at', 'least', 'message', 'back', 'saying', 'anything', 'possibly', 'a', 'hey', 'i', 'am', 'super', 'busy', 'and', 'i', 'would', 'be', 'happy', 'and', 'understanding', 'very', 'disappointed']\n","comment    0\n","rating     0\n","y          0\n","token      0\n","ltoken     0\n","dtype: int64\n","ltoken with len < 1: 22\n"]}]},{"cell_type":"code","metadata":{"id":"1icd1qUqEISr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637586373862,"user_tz":-60,"elapsed":62063,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"3585b5d6-f3f6-452f-e2d3-044195ed2f29"},"source":["stop.extend(['good', 'bad', 'dont', 'many', 'love', 'excellent', 'would', 'perfect', 'even', 'great','nice', 'amazing'])\n","my_stop_words = []\n","stop.extend(my_stop_words)\n","\n","df['ltoken'] = df.ltoken.apply(lambda row: [item for item in row if item not in my_stop_words])\n","\n","df['stopwords'] = df.ltoken.apply(lambda row: [item for item in row if item in stop])\n","df['nostopwords'] = df.ltoken.apply(lambda row: [item for item in row if item not in stop])\n","\n","df.isna().sum()"],"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["comment        0\n","rating         0\n","y              0\n","token          0\n","ltoken         0\n","stopwords      0\n","nostopwords    0\n","dtype: int64"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"dItqZS9DJkVU"},"source":["\n","bigram  = Phrases(df.ltoken, min_count=5, threshold=0.2, common_terms=connectors) #gensim 3, ad esempio \"and\" \n","df['bigrams_afternostop'] = df.ltoken.apply(lambda row: bigram[row])\n","\n","ngram   = Phrases(df.bigrams_afternostop, min_count=5, threshold=0.2, common_terms=connectors) # gensim 3\n","df['ngrams_afternostop'] = df.bigrams_afternostop.apply(lambda row: ngram[row])\n","\n","df.bigrams_afternostop = df.bigrams_afternostop.apply(lambda bigr: [item for item in bigr if item not in stop])\n","df.ngrams_afternostop = df.ngrams_afternostop.apply(lambda ngr: [item for item in ngr if item not in stop])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AezIVSZzKkN1"},"source":["bigram  = Phrases(df.nostopwords, min_count=20, threshold=0.2, common_terms=connectors) #gensim 3, ad esempio \"and\" \n","df['bigrams_beforenostop'] = df.nostopwords.apply(lambda row: bigram[row])\n","\n","ngram   = Phrases(df.bigrams_beforenostop, min_count=20, threshold=0.2, common_terms=connectors) # gensim 3\n","df['ngrams_beforenostop'] = df.bigrams_beforenostop.apply(lambda row: ngram[row])\n","\n","df['bigrams_afternostop_sent'] = df.bigrams_afternostop.apply(lambda row: ' '.join(row))\n","df['bigrams_beforenostop_sent'] = df.bigrams_beforenostop.apply(lambda row: ' '.join(row))\n","df['ngrams_afternostop_sent'] = df.ngrams_afternostop.apply(lambda row: ' '.join(row))\n","df['ngrams_beforenostop_sent'] = df.ngrams_beforenostop.apply(lambda row: ' '.join(row))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Ku8RhMvSx2u"},"source":["\n","df.bigrams_afternostop_sent = df.bigrams_afternostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","df.bigrams_beforenostop_sent = df.bigrams_beforenostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","df.ngrams_afternostop_sent = df.ngrams_afternostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","df.ngrams_beforenostop_sent = df.ngrams_beforenostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","\n","print(len(df))\n","df = df[~(df.bigrams_afternostop_sent.str.len() == 0)]\n","df = df[~(df.bigrams_beforenostop_sent.str.len() == 0)]\n","df = df[~(df.ngrams_afternostop_sent.str.len() == 0)]\n","df = df[~(df.ngrams_beforenostop_sent.str.len() == 0)]\n","print(len(df))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yaVoykP4ENSz"},"source":["\n","\n","# print(df.isna().sum())\n","len_target = 1\n","for field_name in ['token', 'ltoken'\n","              ,'bigrams_afternostop_sent' \n","              ,'bigrams_beforenostop_sent'\n","              ,'ngrams_afternostop_sent'  \n","              ,'ngrams_beforenostop_sent']: \n","  counter = df[df[field_name].str.len() < len_target][field_name].count()\n","  print(f'{field_name} with len < {len_target}: {counter}')\n","\n","n = 10\n","print(f'df.bigrams_afternostop_sent[{n}] : {df.bigrams_afternostop_sent.to_list()[n]}')\n","print(f'df.bigrams_beforenostop_sent[{n}]: {df.bigrams_beforenostop_sent.to_list()[n]}')\n","print(f'df.ngrams_afternostop_sent[{n}]  : {df.ngrams_afternostop_sent.to_list()[n]}')\n","print(f'df.ngrams_beforenostop_sent[{n}] : {df.ngrams_beforenostop_sent.to_list()[n]}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KcfSpnliM0Dt"},"source":["df_saving = df.copy()\n","df_saving = df_saving.loc[:, ['comment', 'rating', \n","                      'bigrams_afternostop_sent',\n","                      'bigrams_beforenostop_sent', \n","                      'ngrams_afternostop_sent',\n","                      'ngrams_beforenostop_sent'\n","                      ,'y']]\n","saving_file_name = f'{tone_root_dir}trustpilot_ready4_bow.csv'\n","df_saving.to_csv(saving_file_name, index=False, encoding='utf-8', sep =',' )\n","df_saving.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"avG5NFW_PaG-"},"source":["## 6.3 BOW"]},{"cell_type":"code","metadata":{"id":"UGQ3bcvQNgA2","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1637587511517,"user_tz":-60,"elapsed":8913,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"4a52c504-328a-4e28-a2eb-ca2763a7375f"},"source":["df_open = pd.read_csv(f'{tone_root_dir}trustpilot_ready4_bow.csv', encoding='utf-8', sep =',', header=0 )\n","\n","# df.bigrams_afternostop_sent = df.bigrams_afternostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","# df.bigrams_beforenostop_sent = df.bigrams_beforenostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","# df.ngrams_afternostop_sent = df.ngrams_afternostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","# df.ngrams_beforenostop_sent = df.ngrams_beforenostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","\n","# print(len(df_open))\n","# df_open = df_open[~(df_open.bigrams_afternostop_sent.str.len() == 0)]\n","# df_open = df_open[~(df_open.bigrams_beforenostop_sent.str.len() == 0)]\n","# df_open = df_open[~(df_open.ngrams_afternostop_sent.str.len() == 0)]\n","# df_open = df_open[~(df_open.ngrams_beforenostop_sent.str.len() == 0)]\n","# print(len(df_open))\n","\n","print(df_open.isna().sum())\n","df_open.head()"],"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["comment                      0\n","rating                       0\n","bigrams_afternostop_sent     0\n","bigrams_beforenostop_sent    0\n","ngrams_afternostop_sent      0\n","ngrams_beforenostop_sent     0\n","y                            0\n","dtype: int64\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>comment</th>\n","      <th>rating</th>\n","      <th>bigrams_afternostop_sent</th>\n","      <th>bigrams_beforenostop_sent</th>\n","      <th>ngrams_afternostop_sent</th>\n","      <th>ngrams_beforenostop_sent</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>This product is awesome! Super helpful with the nerve damage sustained from a dog bit incident. Couldnt recommended a better product</td>\n","      <td>1</td>\n","      <td>product awesome super_helpful nerve_damage sustained dog_bit incident couldnt recommended better_product</td>\n","      <td>product awesome super_helpful nerve damage sustained dog bit incident couldnt recommended better_product</td>\n","      <td>product awesome super_helpful nerve_damage sustained dog_bit incident couldnt recommended better_product</td>\n","      <td>product awesome super_helpful nerve damage sustained dog bit incident couldnt recommended better_product</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Super safe helmet and very comfortable</td>\n","      <td>1</td>\n","      <td>super safe helmet comfortable</td>\n","      <td>super safe helmet comfortable</td>\n","      <td>super safe helmet comfortable</td>\n","      <td>super safe helmet comfortable</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I am pretty frustrated with him! My boyfriend decided to buy me one of the buffalo bags! He ordered it back in October and the at the time the website stated 3-4 to weeks and it would be sent out! He also accepted the money! We have tried and tried to talk to him and he ignores messages, he messaged back once! 11 weeks later and he is still ignoring us! Very very disappointed! I would love to support his work as it a gorgeous but he is sure it making it hard! He could at least message back... saying anything, possibly a hey I am super busy and I would be happy and understanding. Very disappointed!!!</td>\n","      <td>1</td>\n","      <td>pretty frustrated him boyfriend decided_to_buy one buffalo bags ordered back_in_october time website_stated 3 4 week would_be_sent out also accepted money tried_and_tried talk ignores messages messaged_back once 11_week later still_ignoring us disappointed would_love support work gorgeous sure making hard could_at_least message back saying anything possibly hey super busy would_be_happy understanding disappointed</td>\n","      <td>pretty frustrated him boyfriend decided_buy one buffalo bags ordered_back october time website_stated 3 4_week sent out also accepted money tried tried_talk ignores messages messaged back once 11 week_later still ignoring us disappointed support work gorgeous sure making hard could_least message back saying anything possibly hey super busy happy understanding disappointed</td>\n","      <td>pretty frustrated him boyfriend decided_to_buy one buffalo bags ordered back_in_october time website_stated 3 4 week would_be_sent out also accepted money tried_and_tried talk ignores messages messaged_back once 11_week later still_ignoring us disappointed would_love support work gorgeous sure making hard could_at_least message back saying anything possibly hey super busy would_be_happy understanding disappointed</td>\n","      <td>pretty frustrated him boyfriend decided_buy one buffalo bags ordered_back october time website_stated 3 4_week sent out also accepted money tried tried_talk ignores messages messaged back once 11 week_later still ignoring us disappointed support work gorgeous sure making hard could_least message back saying anything possibly hey super busy happy understanding disappointed</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stealing my money!!! Ordered a coat and returned it. Still waiting for refund 45 days later. They have n o excuse except to blame it on my bank...which is not correct, as I work in the POS industry.  As of now they have stolen from me, and they do not care at all. Horrible!</td>\n","      <td>1</td>\n","      <td>stealing money ordered_a_coat returned_it still_waiting refund 45_day later n excuse except blame bank which correct work po industry stolen me care_at_all horrible</td>\n","      <td>stealing money ordered coat returned_it still_waiting refund 45_day later n excuse except blame bank which correct work po industry stolen me care_all horrible</td>\n","      <td>stealing money ordered_a_coat returned_it still_waiting_for_refund 45_day later n excuse except blame bank which correct work po industry stolen me care_at_all horrible</td>\n","      <td>stealing money ordered coat returned_it still_waiting_refund 45_day later n excuse except blame bank which correct work po industry stolen me care_all horrible</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I have researched and live-chatted with this company. Most of the credible reviews have been negative. A few of the glowing, over-the-top, positive reviews appear shady, with poor grammar and syrupy-sweet comments....</td>\n","      <td>1</td>\n","      <td>researched live chatted company credible review negative glowing over the top positive_review appear shady poor_grammar syrupy sweet comments</td>\n","      <td>researched live chatted company credible review negative glowing over the top positive_review appear shady poor grammar syrupy sweet comments</td>\n","      <td>researched live chatted company credible review negative glowing over the top positive_review appear shady poor_grammar syrupy sweet comments</td>\n","      <td>researched live chatted company credible review negative glowing over the top positive_review appear shady poor grammar syrupy sweet comments</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          comment  ...  y\n","0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            This product is awesome! Super helpful with the nerve damage sustained from a dog bit incident. Couldnt recommended a better product  ...  0\n","1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Super safe helmet and very comfortable  ...  0\n","2  I am pretty frustrated with him! My boyfriend decided to buy me one of the buffalo bags! He ordered it back in October and the at the time the website stated 3-4 to weeks and it would be sent out! He also accepted the money! We have tried and tried to talk to him and he ignores messages, he messaged back once! 11 weeks later and he is still ignoring us! Very very disappointed! I would love to support his work as it a gorgeous but he is sure it making it hard! He could at least message back... saying anything, possibly a hey I am super busy and I would be happy and understanding. Very disappointed!!!  ...  0\n","3                                                                                                                                                                                                                                                                                                                                              Stealing my money!!! Ordered a coat and returned it. Still waiting for refund 45 days later. They have n o excuse except to blame it on my bank...which is not correct, as I work in the POS industry.  As of now they have stolen from me, and they do not care at all. Horrible!  ...  0\n","4                                                                                                                                                                                                                                                                                                                                                                                                       I have researched and live-chatted with this company. Most of the credible reviews have been negative. A few of the glowing, over-the-top, positive reviews appear shady, with poor grammar and syrupy-sweet comments....  ...  0\n","\n","[5 rows x 7 columns]"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_myIwXezxPS8","executionInfo":{"status":"ok","timestamp":1637586773469,"user_tz":-60,"elapsed":193,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"b3df78f7-645a-4363-d817-f4227795466a"},"source":["df_open.columns"],"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['comment', 'rating', 'bigrams_afternostop_sent',\n","       'bigrams_beforenostop_sent', 'ngrams_afternostop_sent',\n","       'ngrams_beforenostop_sent', 'y'],\n","      dtype='object')"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"w58Xsm58Pfok","executionInfo":{"status":"ok","timestamp":1637587546335,"user_tz":-60,"elapsed":8497,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}}},"source":["import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","\n","df = df_open.copy()\n","# number_of_row = 1000\n","# # number_of_row = len(df['y'] == 1])\n","# df = df[df['y'] == 1].sample(number_of_row, random_state= 123).append(df[df['y'] == 0].sample(number_of_row, random_state= 123))\n","# print(f'reduced df len: {len(df)}')\n","# # 'comment', 'rating', 'bigrams_afternostop_sent',\n","# #        'bigrams_beforenostop_sent', 'ngrams_afternostop_sent',\n","# #        'ngrams_beforenostop_sent', 'y'\n","\n","# choosen_column_2vec = 'ngrams_afternostop_sent'\n","\n","# vectorizer = CountVectorizer(ngram_range=(1, 1), max_features=1000)\n","# # vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=1000)\n","\n","# model_filename = f\"{models_root_dir}our_bow_dict_model.pkl\"\n","# with open(model_filename, 'rb') as file:\n","#     vectorizer = pickle.load(file)\n","\n","X = vectorizer.fit_transform(df['ngrams_beforenostop_sent'].to_list())\n","# # feature_names = vectorizer.get_feature_names()\n","# # print(feature_names)\n","\n","X = X.toarray()\n","X = np.array(X)\n","y = np.array(df['y'].to_list())\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"id":"VTLDlWeGbVDQ"},"source":["all_ngrams = []\n","for ngram_list in df.ngrams_afternostop_sent.to_list():\n","  all_ngrams.extend(ngram_list.split())\n","\n","from collections import Counter\n","counter = Counter(all_ngrams)\n","counter.most_common(1000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JXmblkksyWfj"},"source":["feature_names = vectorizer.get_feature_names()\n","feature_names[:100]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"igbKAnS0VhMm"},"source":["from tqdm import tqdm\n","from sklearn import tree\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import StratifiedKFold, cross_val_score\n","from sklearn.metrics import accuracy_score, recall_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","import pickle\n","\n","#################################################################################√†\n","tree_model = tree.DecisionTreeClassifier(max_leaf_nodes=10, max_depth=5)\n","#################################################################################√†\n","tree_model.fit(x_train, y_train)\n","\n","# Save to file in the current working directory\n","model_filename = f\"{models_root_dir}our_bow_dict_model.pkl\"\n","# Load from file\n","with open(model_filename, 'rb') as file:\n","    tree_model = pickle.load(file)\n","\n","predicted = tree_model.predict(x_test)\n","print(f'tree_model: {classification_report(y_test, predicted)}')\n","\n","#################################################################################√†\n","logit_model = LogisticRegression(class_weight=None)\n","#################################################################################√†\n","logit_model.fit(x_train, y_train)\n","\n","# Save to file in the current working directory\n","model_filename = f\"{models_root_dir}basic_logit_model.pkl\"\n","with open(model_filename, 'wb') as file:\n","    pickle.dump(logit_model, file)\n","# Load from file\n","with open(model_filename, 'rb') as file:\n","    logit_model = pickle.load(file)\n","\n","predicted = logit_model.predict(x_test)\n","print(f'logit_model: {classification_report(y_test, predicted)}')\n","\n","\n","#################################################################################√†\n","random_model = RandomForestClassifier()\n","#################################################################################√†\n","random_model.fit(x_train, y_train)\n","\n","# Save to file in the current working directory\n","model_filename = f\"{models_root_dir}basic_random_model.pkl\"\n","with open(model_filename, 'wb') as file:\n","    pickle.dump(random_model, file)\n","# Load from file\n","with open(model_filename, 'rb') as file:\n","    random_model = pickle.load(file)\n","\n","predicted = random_model.predict(x_test)\n","print(f'random_model: {classification_report(y_test, predicted)}')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jpxFJs7uytJe"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eOBsslToysP2"},"source":[""],"execution_count":null,"outputs":[]}]}
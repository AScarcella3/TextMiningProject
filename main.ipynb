{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":["NTbyaABttqTU","-3VBjqnb-JBS","NEWRZ27yARuf","iY28vhKQN5M4","p_O5Tw5nhIPI","TcwnFQNa-t_K","UfFzJp30Yp6r"],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hzolRRT_ANfT"},"source":["# Path e librerie\n","## Prima di modificare avvertire gli altri!"]},{"cell_type":"markdown","metadata":{"id":"NvLbCq-Etlj-"},"source":["## Install"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WkMr6gJYuiBg","tags":[],"executionInfo":{"status":"ok","timestamp":1637680913864,"user_tz":-60,"elapsed":18895,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"7b4ea995-1e39-4ff0-e256-91fb85726ce5"},"source":["#import drive dir\n","from google.colab import drive\n","drive_dir = 'drive' ; \n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"L0f-_Htz-GUP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637680988366,"user_tz":-60,"elapsed":70865,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"148744f4-dc19-4702-f9bb-ac47d6f2b876"},"source":["!pip install polyglot\n","!pip install PyICU\n","!pip install pycld2\n","!pip install morfessor"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting polyglot\n","  Downloading polyglot-16.7.4.tar.gz (126 kB)\n","\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 38.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 37.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 36.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 81 kB 31.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92 kB 33.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 36.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 112 kB 36.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122 kB 36.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 126 kB 36.1 MB/s \n","\u001b[?25hBuilding wheels for collected packages: polyglot\n","  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52578 sha256=c68973e90de9d5f9b15413528324cf6d21c8a0412fb9b18a2e1eaba207d3672f\n","  Stored in directory: /root/.cache/pip/wheels/09/bc/67/75c9de8e9726460bc0b101ad225ad025cb8ce9e0759beb9d52\n","Successfully built polyglot\n","Installing collected packages: polyglot\n","Successfully installed polyglot-16.7.4\n","Collecting PyICU\n","  Downloading PyICU-2.8.tar.gz (299 kB)\n","\u001b[K     |████████████████████████████████| 299 kB 32.6 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: PyICU\n","  Building wheel for PyICU (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyICU: filename=PyICU-2.8-cp37-cp37m-linux_x86_64.whl size=1377130 sha256=bdf61be8cbae56ae2a9edd0b60b63d86986055d1ff951949689dfe8758539d5f\n","  Stored in directory: /root/.cache/pip/wheels/14/bd/45/aeddc643bd0637c14fa27bffaee5b411cdc323f8bec76ad15e\n","Successfully built PyICU\n","Installing collected packages: PyICU\n","Successfully installed PyICU-2.8\n","Collecting pycld2\n","  Downloading pycld2-0.41.tar.gz (41.4 MB)\n","\u001b[K     |████████████████████████████████| 41.4 MB 1.2 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pycld2\n","  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycld2: filename=pycld2-0.41-cp37-cp37m-linux_x86_64.whl size=9834313 sha256=6ae377d465a1c69830f702c584417e0cba219db79a405332370889082bff8ea4\n","  Stored in directory: /root/.cache/pip/wheels/ed/e4/58/ed2e9f43c07d617cc81fe7aff0fc6e42b16c9cf6afe960b614\n","Successfully built pycld2\n","Installing collected packages: pycld2\n","Successfully installed pycld2-0.41\n","Collecting morfessor\n","  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n","Installing collected packages: morfessor\n","Successfully installed morfessor-2.0.6\n"]}]},{"cell_type":"markdown","metadata":{"id":"bFQ8FsKNtnrr"},"source":["## Import"]},{"cell_type":"code","metadata":{"id":"W2rdoygctsrH"},"source":["import tweepy\n","import numpy as np\n","from tweepy import Stream, OAuthHandler\n","from tqdm.notebook import tqdm\n","# from tqdm import tqdm !! per Jupyter from tqdm.notebook non funziona, runnare questo\n","import pandas as pd\n","pd.set_option('display.max_colwidth', None) # setta il num. di caratteri visibili per ogni cella della colonna\n","# es. 50 = primi 50 caratteri\n","# None = testo completo\n","\n","import io\n","import pprint\n","import os\n","import glob\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from polyglot.detect import Detector\n","import icu\n","import csv\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NTbyaABttqTU","tags":[]},"source":["## Path per Colab"]},{"cell_type":"code","metadata":{"id":"eeZCfUCeuglG"},"source":["##########################\n","### ROOT\n","##########################\n","\n","prj_root_dir = f'/content/{drive_dir}/MyDrive/nucleare/'\n","os.makedirs(prj_root_dir, exist_ok=True)\n","\n","##########################\n","### SCRAPING: file dello scraping di ATP\n","##########################\n","\n","scrapingATP_root_dir = prj_root_dir + 'scrapingATP/'\n","os.makedirs(scrapingATP_root_dir, exist_ok=True)\n","\n","##########################\n","### ETL: \n","##########################\n","\n","etl_root_dir = prj_root_dir + 'ETL/'\n","os.makedirs(etl_root_dir, exist_ok=True)\n","\n","##########################\n","### DWH\n","##########################\n","\n","dw_root_dir = prj_root_dir + 'DWH/'\n","os.makedirs(dw_root_dir, exist_ok=True)\n","\n","##########################\n","### SENTIMENT\n","##########################\n","\n","sentiment_root_dir = prj_root_dir + 'SENTIMENT/'\n","os.makedirs(sentiment_root_dir, exist_ok=True)\n","\n","##########################\n","### WORDEMBEDDING\n","##########################\n","\n","embedding_root_dir = prj_root_dir + 'EMBEDDING/'\n","os.makedirs(embedding_root_dir, exist_ok=True)\n","\n","##########################\n","### OUTPUT\n","##########################\n","\n","output_root_dir = prj_root_dir + 'OUTPUT/'\n","os.makedirs(output_root_dir, exist_ok=True)\n","\n","##########################\n","### MODELS\n","##########################\n","\n","models_root_dir = prj_root_dir + 'MODELS/'\n","os.makedirs(models_root_dir, exist_ok=True)\n","\n","##########################\n","### STAGING ANTONELLO M.\n","##########################\n","\n","st_man_root_dir = prj_root_dir + 'STAGING_MANENTI/'\n","os.makedirs(st_man_root_dir, exist_ok=True)\n","\n","\n","##########################\n","### STAGING TONE\n","##########################\n","\n","st_tone_root_dir = prj_root_dir + 'STAGING_TONE/'\n","os.makedirs(st_tone_root_dir, exist_ok=True)\n","\n","##########################\n","### STAGING MARCO\n","##########################\n","\n","st_marco_root_dir = prj_root_dir + 'STAGING_MARCO/'\n","os.makedirs(st_marco_root_dir, exist_ok=True)\n","\n","##########################\n","### STAGING NATALIA\n","##########################\n","\n","st_natalia_root_dir = prj_root_dir + 'STAGING_NATALIA/'\n","os.makedirs(st_natalia_root_dir, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":true,"tags":[],"id":"DF6_OdTnXf3W"},"source":["### Path per Jupyter\n","Solo quando si usa Jupyter runnare, il percorso dovrebbe essere lo stesso per tutti/e"]},{"cell_type":"code","metadata":{"id":"5ttVa0GiXf3X"},"source":["##########################\n","### ROOT\n","##########################\n","\n","drive_dir = f'G:\\\\My Drive'\n","prj_root_dir = f'{drive_dir}\\\\nucleare\\\\'\n","\n","##########################\n","### SCRAPING\n","##########################\n","\n","scrapingATP_root_dir = prj_root_dir + 'scrapingATP\\\\'\n","\n","##########################\n","### ETL\n","##########################\n","\n","etl_root_dir = prj_root_dir + 'ETL\\\\'\n","\n","##########################\n","### DWH\n","##########################\n","\n","dw_root_dir = prj_root_dir + 'DWH\\\\'\n","\n","##########################\n","### SENTIMENT\n","##########################\n","\n","sentiment_root_dir = prj_root_dir + 'SENTIMENT\\\\'\n","\n","##########################\n","### WORDEMBEDDING\n","##########################\n","\n","embedding_root_dir = prj_root_dir + 'EMBEDDING\\\\'\n","\n","##########################\n","### OUTPUT\n","##########################\n","\n","output_root_dir = prj_root_dir + 'OUTPUT\\\\'\n","\n","##########################\n","### STAGING ANTONELLO M.\n","##########################\n","\n","st_man_root_dir = prj_root_dir + 'STAGING_MANENTI\\\\'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-3VBjqnb-JBS"},"source":["# 1. Ingest\n","## Antonello\n","\n","cartella di scraping: nulceare/scrapingATP"]},{"cell_type":"markdown","metadata":{"id":"NEWRZ27yARuf"},"source":["## Codici Twitter"]},{"cell_type":"code","metadata":{"id":"8MQLVouV-ywL"},"source":["consumer_key = 'WYOB4KubrmdOM9ycdyGvBLkTa'# API Key\n","consumer_secret = 'AThpoW6fKDm6bwZYeO0C0AVM7jKVq0bVgU7w9VfMejrnkygBTK' # APY Secret Key\n","access_token = '1396896479525097474-2HgbagRtx3ByeO4zmkWSPaL1iOxEiH'\n","access_secret = 'IKvhdjwGMDky2dAN6OYdeMZhWUHYheqTmMEWdgcInXf4F'\n","auth = OAuthHandler(consumer_key, consumer_secret)\n","auth.set_access_token(access_token, access_secret)\n","api = tweepy.API(auth, wait_on_rate_limit=True)\n","\n","# consumer_key = 'MQXChIn29dCky3pOQyW890Uxi'\n","# consumer_secret = 'u4n3UeFz58b4H6InWFhBDUPZsfJ8xdVS0wODdnfAjz6e6PUbCJ'\n","# access_token = '262247836-oWkm6AZIw4K0Fldnt8VBXwuL9IbtNCZwVj73ODkI'\n","# access_secret = 'GySGl7BGaYvmXUtCapu5pHwEDHD5tA3Qd4yCMIDPKm1Wx'\n","# auth = OAuthHandler(consumer_key, consumer_secret)\n","# auth.set_access_token(access_token, access_secret)\n","# api = tweepy.API(auth, wait_on_rate_limit=True)\n","\n","# consumer_key = 'Vzk6O5t967f1n4iz9iQcsQwhf'\n","# consumer_secret = 'Q8sncdY1j85mwNitOqb5Spcg6U6uuZ0E2KNHHZEYF2J4DdCyVi'\n","# access_token = '164224789-mFmU5YhessCNvubNojgfL605tbU0vh0NOna3HdQU'\n","# access_secret = 'Ic5LNOH2QqxziSq4eTQdJvbXo3noTcQDUzCKXgFcdPzpC'\n","# auth = OAuthHandler(consumer_key, consumer_secret)\n","# auth.set_access_token(access_token, access_secret)\n","# api = tweepy.API(auth, wait_on_rate_limit=True)\n","\n","# consumer_key = 'A4GRiWdUDgiGPckQSykzA'\n","# consumer_secret = 'nSyjpFDTr3eEmd8tFeBM1lwVrTNPLaHrcx0DicTEEuw'\n","# access_token = '1678747572-lbkg1jxpe5HypoTRSnRMeiVIe0RBMxhdjLJ0GJ6'\n","# access_secret = '1qVP0pHXV9HDgKhHDIy2HHqqnHFBm3sI5AR2ZDwZxlM'\n","# auth = OAuthHandler(consumer_key, consumer_secret)\n","# auth.set_access_token(access_token, access_secret)\n","# api = tweepy.API(auth, wait_on_rate_limit=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ijK4Lyzl-e04"},"source":["utente = 'antonello' #mettere il proprio nome\n","lang = 'all' #mettere la lingua\n","prog = '20' #mettere il progressivo"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SUTCU3yzAdJT"},"source":["## Scraping dello storico"]},{"cell_type":"code","metadata":{"id":"67C67NvV-8Da"},"source":["#mettere la query\n","query_00 = ('NittoATPFinals' or 'TennisTakesOverTorino' or '#ATPFinals' or 'ATPFinals' or 'ATP Finals' or 'Norrie' or '#Norrie' or '@cam_norrie' or 'Norrie' or '#Norrie' or '@cam_norrie' or 'Ruud' or '#Ruud' or '@CasperRuud98' or 'Rublev' or '#Rublev' or '@AndreyRublev97' or 'Tsitsipas' or '#Tsitsipas' or '@steftsitsipas' or 'Djokovic' or '#Djokovic' or '@DjokerNole' or 'Sinner' or '#Sinner' or '@janniksin' or 'Medvedev' or '#Medvedev' or '@DaniilMedwed' or 'Zverev' or '#Zverev' or '@AlexZverev' 'Berrettini' or '#Berrettini' or '@MattBerrettini' or 'Hurkacz' or '#Hurkacz' or '@HubertHurkacz')\n","query_01 = ('@DaniilMedwed' or 'Medvedev' or '#Medvedev' or '@AlexZverev' or 'Zverev' or '#Zverev' or '#NittoATPFinals' or 'NittoATPFinals' or 'TennisTakesOverTorino' or '#ATPFinals' or 'ATPFinals' or 'ATP Finals')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O2bvjFrw_9F8"},"source":["searched_tweets = []\n","last_id = -1\n","max_tweets = 500_000\n","pbar = tqdm(total=max_tweets)\n","\n","while len(searched_tweets) < max_tweets:\n","    count = max_tweets - len(searched_tweets)\n","    try:\n","        # api.search è un metodo che su colab funziona anche se non è documentato in Tweepy. Su Jupyter non funziona, sostituire con search_tweets\n","        new_tweets = api.search(q=query_01, count=1000, max_id=str(last_id - 1), tweet_mode=\"extended\") # tweet_mode=\"extended\" importante, altrimenti il testo del tweet viene troncato\n","        # If I've reached the end of the search then I'm done\n","        # immediately the cycle while\n","        if not new_tweets:\n","            break\n","        # added the data found to the list\n","        searched_tweets.extend(new_tweets)\n","        # tqdm\n","        pbar.update(len(new_tweets))\n","        # retrieve the last id found\n","        last_id = new_tweets[-1].id\n","    except tweepy.TweepError as e:\n","        print(e)\n","        break\n","\n","pbar.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"caBAPyk4AhPM"},"source":["print('Totale Tweet')\n","len(searched_tweets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTakPozJQN82"},"source":["dict_ = {'id': [], 'user': [], 'date': [], 'text': [], \n","         'favorite_count': [], 'hashtags': [], \n","         'location': [], 'retweet': [], 'retweet_count': [], 'followers_count': [], 'in_reply_to_status_id':[], 'user_mentions':[]}\n","\n","for status_j in searched_tweets[0:max_tweets]:\n","    status = status_j._json\n","\n","    if 'retweeted_status' in status:\n","      if 'extended_tweet' in status['retweeted_status']:\n","        text = status['retweeted_status']['extended_tweet']['full_text']\n","        dict_['text'].append(text)\n","      else:\n","        text = status['retweeted_status']['full_text']\n","        dict_['text'].append(text)\n","    else:\n","      if 'extended_tweet' in status:\n","        text = status['extended_tweet']['full_text']\n","        dict_['text'].append(text)\n","      else:\n","        text = status['full_text']\n","        dict_['text'].append(text)\n","    \n","    dict_['id'].append(status['id'])\n","    dict_['user'].append(status['user']['screen_name'])\n","    dict_['hashtags'].append([hashtag['text'] for hashtag in status['entities']['hashtags']])\n","    dict_['user_mentions'].append([user_mention['screen_name'] for user_mention in status['entities']['user_mentions']])\n","    dict_['location'].append(status['user']['location'])\n","    dict_['followers_count'].append(status['user']['followers_count'])\n","    dict_['in_reply_to_status_id'].append(status['in_reply_to_status_id'])\n","    dict_['date'].append(status['created_at'])\n","    dict_['favorite_count'].append(status['favorite_count'])\n","    dict_['retweet_count'].append(status['retweet_count'])\n","    dict_['retweet'].append(status['retweeted'])\n","\n","df = pd.DataFrame.from_dict(dict_, orient=\"columns\")\n","df = df.set_index(\"id\")\n","df.sort_values(by=['date'], inplace=True, ascending=True)\n","df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bEMYyh7EQYiO"},"source":["df = pd.DataFrame.from_dict(dict_, orient=\"columns\")\n","df = df.set_index(\"id\")\n","df.sort_values(by=['date'], inplace=True, ascending=True)\n","df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"etTJY7DM_XrJ"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PCHC8WmOA98e"},"source":["print(df.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFJs4Pl-_KcU"},"source":["df.to_csv(f'{scrapingATP_root_dir}twitter_history_{utente}_{prog}_{lang}_{len(searched_tweets)}.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0MzvdZSU_AWe"},"source":["## Scraping dello stream"]},{"cell_type":"code","metadata":{"id":"eqFqbRuR_lGM"},"source":["class MyStreamListener(tweepy.StreamListener):\n","    data = [] #qui ci metto i tweet che scarico man mano\n","    num = 0 #questo è un contatore settato a 0\n","\n","    def store(self):\n","      dict_ = {'id': [], 'user': [], 'date': [], 'text': [],\n","         'favorite_count': [], 'hashtags': [], \n","         'location': [], 'retweet': [], 'retweet_count': [], 'followers_count': [], 'in_reply_to_status_id':[], 'user_mentions':[]}\n","      \n","      for status_j in self.data:\n","          status = status_j._json\n","\n","          if 'retweeted_status' in status:\n","            if 'extended_tweet' in status['retweeted_status']:\n","              text = status['retweeted_status']['extended_tweet']['full_text']\n","              dict_['text'].append(text)\n","            else:\n","              text = status['retweeted_status']['full_text']\n","              dict_['text'].append(text)\n","          else:\n","            if 'extended_tweet' in status:\n","              text = status['extended_tweet']['full_text']\n","              dict_['text'].append(text)\n","            else:\n","              text = status['full_text']\n","              dict_['text'].append(text)\n","\n","          dict_['id'].append(status['id'])\n","          dict_['user'].append(status['user']['screen_name'])\n","          dict_['hashtags'].append([hashtag['text'] for hashtag in status['entities']['hashtags']])\n","          dict_['user_mentions'].append([user_mention['screen_name'] for user_mention in status['entities']['user_mentions']])\n","          dict_['location'].append(status['user']['location'])\n","          dict_['followers_count'].append(status['user']['followers_count'])\n","          dict_['in_reply_to_status_id'].append(status['in_reply_to_status_id'])\n","          dict_['date'].append(status['created_at'])\n","          dict_['full_text'].append(status['full_text'])\n","          dict_['favorite_count'].append(status['favorite_count'])\n","          dict_['retweet_count'].append(status['retweet_count'])\n","          dict_['retweet'].append(status['retweeted'])\n","\n","      df = pd.DataFrame.from_dict(dict_, orient=\"columns\")\n","      df = df.set_index(\"id\")\n","      df.sort_values(by='favorite_count', inplace=True, ascending=False)\n","      df.to_csv(f'{scrapingATP_root_dir}_twitter_stream_{utente}_{prog}_{lang}_' + str(self.num) + '.csv') #salvo in csv\n","      self.num = self.num + 1\n","      self.data = []\n","\n","\n","    def on_status(self, status):\n","        self.data.append(status)\n","        # to pandas\n","        # store su google drive\n","        if len(self.data) > 5000:\n","          self.store()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I7tJCy-B_pAf"},"source":["myStreamListener = MyStreamListener()\n","myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener, tweet_mode=\"extended\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sY7zHFiI_ptN"},"source":["query_00 = ('NittoATPFinals' or 'TennisTakesOverTorino' or '#ATPFinals' or 'ATPFinals' or 'ATP Finals' or 'Norrie' or '#Norrie' or '@cam_norrie' or 'Norrie' or '#Norrie' or '@cam_norrie' or 'Ruud' or '#Ruud' or '@CasperRuud98' or 'Rublev' or '#Rublev' or '@AndreyRublev97' or 'Tsitsipas' or '#Tsitsipas' or '@steftsitsipas' or 'Djokovic' or '#Djokovic' or '@DjokerNole' or 'Sinner' or '#Sinner' or '@janniksin' or 'Medvedev' or '#Medvedev' or '@DaniilMedwed' or 'Zverev' or '#Zverev' or '@AlexZverev' 'Berrettini' or '#Berrettini' or '@MattBerrettini' or 'Hurkacz' or '#Hurkacz' or '@HubertHurkacz')\n","query_01 = ['@DaniilMedwed' or 'Medvedev' or '#Medvedev' or '@AlexZverev' or 'Zverev' or '#Zverev' or '#NittoATPFinals' or 'NittoATPFinals' or 'TennisTakesOverTorino' or '#ATPFinals' or 'ATPFinals' or 'ATP Finals']\n","myStream.filter(track=query_01)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvUTo5db_ulg"},"source":["len(myStreamListener.data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Od_-LHco_yh6"},"source":["dict_ = {'id': [], 'user': [], 'date': [], 'text': [], \n","         'favorite_count': [], 'hashtags': [], \n","         'location': [], 'retweet': [], 'retweet_count': [], 'followers_count': [], 'in_reply_to_status_id':[], 'user_mentions':[]}\n","#\n","for status_j in myStreamListener.data:\n","    status = status_j._json\n","\n","    if 'retweeted_status' in status:\n","      if 'extended_tweet' in status['retweeted_status']:\n","        text = status['retweeted_status']['extended_tweet']['full_text']\n","        dict_['text'].append(text)\n","      else:\n","        text = status['retweeted_status']['text']\n","        dict_['text'].append(text)\n","    else:\n","      if 'extended_tweet' in status:\n","        text = status['extended_tweet']['full_text']\n","        dict_['text'].append(text)\n","      else:\n","        text = status['text']\n","        dict_['text'].append(text)\n","\n","    dict_['id'].append(status['id'])\n","    dict_['user'].append(status['user']['screen_name'])\n","    dict_['hashtags'].append([hashtag['text'] for hashtag in status['entities']['hashtags']])\n","    dict_['user_mentions'].append([user_mention['screen_name'] for user_mention in status['entities']['user_mentions']])\n","    dict_['location'].append(status['user']['location'])\n","    dict_['followers_count'].append(status['user']['followers_count'])\n","    dict_['in_reply_to_status_id'].append(status['in_reply_to_status_id'])\n","    dict_['date'].append(status['created_at'])\n","    dict_['favorite_count'].append(status['favorite_count'])\n","    dict_['retweet_count'].append(status['retweet_count'])\n","    dict_['retweet'].append(status['retweeted'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AxsfeH0r_0YX"},"source":["df = pd.DataFrame.from_dict(dict_, orient=\"columns\")\n","df = df.set_index(\"id\")\n","df.sort_values(by='favorite_count', inplace=True, ascending=False)\n","df.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c6hPQxS3_6fj"},"source":["df.to_csv(f'{scrapingATP_root_dir}twitter_stream_{utente}_{prog}_{lang}_{len(myStreamListener.data)}.csv') #scarico l'ultimo stream"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ypONx-rx_99j"},"source":["#unisco tutti i csv\n","\n","path = scrapingATP_root_dir\n","\n","all_files = glob.glob(os.path.join(path, \"twitter_*.csv\"))\n","df_from_each_file = (pd.read_csv(f, sep=',') for f in all_files)\n","df_merged = pd.concat(df_from_each_file, ignore_index=True)\n","df_merged.drop_duplicates(subset=['id'], inplace=True, ignore_index=False)\n","df_merged.to_csv(f'{etl_root_dir}twitter_merged_from_scraping.csv', index=False, sep=',', encoding='utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5e-bKUNUHtFr"},"source":["df_merge = pd.read_csv(f'{etl_root_dir}twitter_merged_from_scraping.csv')\n","df_merge.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EkyiON6TKi0T"},"source":["df_merge.tail()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iY28vhKQN5M4"},"source":["# 2. ETL\n","**NATALIA**\n","\n","\n","\n","1.   rimuovere #\n","2.   rimuovere id doppi\n","1.   rimuovere http\n","2.   rimuovere twitter con testo vuoto\n","1.   rimuovere @\n","\n","\n","\n","file input: nucleare/ETL/twitter_merged_from_scraping.csv\n","\n","cartella output: nucleare/DWH/"]},{"cell_type":"code","metadata":{"id":"XGHss6_srU9O"},"source":["df = pd.read_csv(etl_root_dir+'twitter_merged_from_scraping.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qEPS35oxtHgf"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wdaWLYkXrU41"},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d28byin7p8vS"},"source":["df.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xjp67njxqzGS"},"source":["with open(dw_root_dir+'twitter_text_cleaned.csv', mode='w') as csv_file_out:\n","  csv_writer_out = csv.writer(csv_file_out, delimiter=',', quotechar='\"')\n","  with open(etl_root_dir+'twitter_merged_from_scraping.csv', mode='r') as csv_file:\n","    csv_reader = csv.reader(csv_file, delimiter=',')\n","    line_count = 0\n","    max_lines=10000000 \n","    monDict = {'Gen' : '01' , 'Feb' : '02', 'Mar' : '03', 'Apr' : '04', 'May' : '05', 'Jun' : '06', 'Jul' : '07', 'Aug' : '08', 'Sep' : '09', 'Oct' : '10', 'Nov' : '11', 'Dic' : '12'}\n","  \n","    for row in csv_reader:\n","          if line_count > 0:\n","              dateCur=row[2]\n","              monCur=monDict[dateCur[4:7]]\n","              dateNew=dateCur[26:30]+'-'+monDict[dateCur[4:7]]+'-'+dateCur[8:10]+' '+dateCur[11:13]+':'+dateCur[14:16]+':'+dateCur[17:19]\n","              timezone='z'+dateCur[20:25]\n","              #print (f'{dateCur} ==> {dateNew}')\n","              textnonl=row[3].replace(\"\\n\",\" \")\n","              textnonl==re.sub(r\"\\s+\",\" \",textnonl) # tolgo doppi spazi\n","              #print (f'message {message}')\n","              textnonlhash=re.sub(r\"#\\w+ ?\",\"\",textnonl)\n","              textnonlhash=re.sub(r\"\\s+\",\" \",textnonlhash)\n","              textnonlhashmen=re.sub(r\"@\\w+ ?\",\"\",textnonlhash)\n","              textnonlhashmen=re.sub(r\"\\s+\",\" \",textnonlhashmen)\n","              textnonlhashmenhttp=re.sub(r\"http\\S+\",\"\",textnonlhashmen)\n","              textnonlhashmenhttp=re.sub(r\"\\s+\",\" \",textnonlhashmenhttp)\n","              textnonlhashmenhttpnum=re.sub(r\"\\d+\", \"\", textnonlhashmenhttp)    \n","              textnonlhashmenhttpnum=re.sub(r\"\\s+\",\" \",textnonlhashmenhttpnum)\n","              textnonlhashmenhttpnumsimb=re.sub(r\"[^\\w\\s]\",\" \",textnonlhashmenhttpnum)\n","              textnonlhashmenhttpnumsimb=re.sub(r\"\\s+\",\" \",textnonlhashmenhttpnumsimb)\n","              row2=row\n","              row2.extend([dateNew,timezone,textnonl,textnonlhash,textnonlhashmen,textnonlhashmenhttp,textnonlhashmenhttpnum,textnonlhashmenhttpnumsimb])\n","              csv_writer_out.writerow(row2)\n","              line_count += 1\n","          else:\n","            row2=row\n","            row2.extend(['date_norm','time_zone','text_nonl','text_nonl_hash','text_nonl_hash_men','text_nonl_hash_men_http','text_nonl_hash_men_http_num','text_nonl_hash_men_http_num_simb'])\n","            csv_writer_out.writerow(row2)\n","            line_count += 1\n","          if line_count > max_lines:\n","              print (f'Exit')\n","              break      \n","    print(f'Processed {line_count} lines.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wV88XWd84_nn"},"source":["df = pd.read_csv(dw_root_dir+'twitter_text_cleaned.csv', sep=',')\n","df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p_O5Tw5nhIPI"},"source":["# 3. Language detection\n","ANTONELLO M."]},{"cell_type":"code","metadata":{"id":"Tq0WsYPT_Dpm"},"source":["df = pd.read_csv(f'{dw_root_dir}twitter_text_cleaned.csv')\n","df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3FqoIvycYfu"},"source":["df.sample(n=5, random_state=13)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SAncVTvN_NeT"},"source":["# testing polyglot\n","df_test = df[['text_nonl_hash_men_http_num_simb', 'text']]\n","df_test = df_test.sample(n=3, random_state=13)\n","df_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5sV7sL1U_PoV"},"source":["df_test['poly_obj'] = df_test.text_nonl_hash_men_http_num_simb.apply(lambda x: Detector(x, quiet=True))\n","df_test['text_lang'] = df_test.poly_obj.apply(lambda x: icu.Locale.getDisplayName(x.language.locale))\n","df_test['text_lan_code'] = df_test.poly_obj.apply( lambda x: x.language.code)\n","df_test['lang_confidence'] = df_test.poly_obj.apply( lambda x: x.language.confidence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x77RVB9m_RtZ"},"source":["df_test.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"icFl1idO_VcV"},"source":["df_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1tv-5mm_ZBF"},"source":["df_test['poly_obj'] = df_test['poly_obj'].astype(str)\n","df_test_predict = df_test['poly_obj'].str.split(\" \", expand=True)\n","df_test_predict.rename(columns={3:'prediction'}, inplace=True)\n","df_test_predict = df_test_predict.drop([0, 1, 2, 4, 5, 6], axis=1)\n","df_test_predict = df_test_predict.iloc[:,0:1]\n","df_test_predict['prediction_reliable'] = df_test_predict['prediction'].str.replace(r'\\n([-A-Za-z0-9_.]+)', '') \n","df_test_predict = df_test_predict.drop(['prediction'], axis=1)\n","df_test = pd.concat([df_test, df_test_predict], axis=1) \n","df_test = df_test.drop(['poly_obj'], axis=1)\n","df_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IZOup7q7_buE"},"source":["# apply polyglot\n","df = df[df['text_nonl_hash_men_http_num_simb'].notna()]\n","df['poly_obj'] = df['text_nonl_hash_men_http_num_simb'].apply(lambda x: Detector(x, quiet=True))\n","df['text_lang'] = df.poly_obj.apply(lambda x: icu.Locale.getDisplayName(x.language.locale))\n","df['text_lan_code'] = df.poly_obj.apply( lambda x: x.language.code)\n","df['lang_confidence'] = df.poly_obj.apply( lambda x: x.language.confidence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KhYcHSeO_eWp"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrIZCo3Wft35"},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfMo8BUD_gO5"},"source":["df['poly_obj'] = df['poly_obj'].astype(str)\n","df_det_lang = df['poly_obj'].str.split(\" \", expand=True)\n","df_det_lang.rename(columns={3:'prediction'}, inplace=True)\n","df_det_lang = df_det_lang.drop([0, 1, 2, 4, 5, 6], axis=1)\n","df_det_lang = df_det_lang.iloc[:,0:1]\n","df_det_lang['prediction_reliable'] = df_det_lang['prediction'].str.replace(r'\\n([-A-Za-z0-9_.]+)', '') \n","df_det_lang = df_det_lang.drop(['prediction'], axis=1)\n","df = pd.concat([df, df_det_lang], axis=1) \n","df = df.drop(['poly_obj'], axis=1)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjE8gyfoc6vC"},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mueC2aBOc7I4"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7VPYm3c5dCEq"},"source":["twe = df['id'].count()\n","lan = df['text_lang'].nunique()\n","print(f'{lan} lingue differenti per {twe} tweet di cui:')\n","df.groupby(['text_lang']).size().nlargest(10).reset_index(name='top10')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SblO-QzZhp27"},"source":["df.to_csv(f'{st_man_root_dir}twitter_text_cleaned_lang_det.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WWjLQ8r__839"},"source":["# 4. Player detection\n","ANTONELLO M."]},{"cell_type":"code","metadata":{"id":"Pn8WFr_PdFzO"},"source":["df = pd.read_csv(f'{st_man_root_dir}twitter_text_cleaned_lang_det.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxdjGVUswYQh"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Tkf_0j_uAwf"},"source":["**Idea**\n","1. Si creano tante colonne quante sono le variabili in list (cella iniziale)\n","2. Se una delle parole definite nella lista (.str.contains) è presente si mette 1 colonna corrispondente corrispondete.\n","3. Se la somma delle nuove colonne è 0 il topic è Other\n","4. Se la somma delle nuove colonne è 1 il topic è il nome della colonna con valore 1.\n","5. Se la somma delle nuove colonne è 2 e ATP Finals = 1 allora il topic è il nome dell'altra colonna\n","6. Se la somma delle nuove colonne è 2 e ATP Finals = 0 allora il topic è il nome previsto da match se le colonne corrispettive sono a 1, altrimenti il topic è il nome di entrambi i giocatori.\n","7. Se la somma delle nuove colonne è 3 e ATP Finals = 1 allora il topic è il nome previsto da match se le colonne corrispettive sono a 1, altrimenti il topic è il nome di tutti i giocatori = 1.\n","8. Se la somma delle nuove colonne è 3 e ATP Finals = 0 il topic sono tutti i nomi dei giocatori = 1.\n","9. Se la somma delle nuove colonne è > 3 il topic è il nome di tutti i giocatori = 1\n","\n","\n","**Match**\n","\n","Djokovic and Ruud = 'Djokovic VS Ruud RR' # RR is Round Robin cioè fase a gironi\n","\n","Rublev and Tsitsipas = 'Rublev VS Tsitsipas RR'\n","\n","Djokovic and Rublev = 'Djokovic VS Rublev RR'\n","\n","Ruud and Norrie = 'Ruud VS Norrie RR'\n","\n","Ruud and Rublev = 'Ruud VS Rublev RR'\n","\n","Djokovic and Norrie = 'Djokovic VS Norrie RR'\n","\n","Medvedev and Hurkacz = 'Medvedev VS Hurkacz RR'\n","\n","Zverev and Berrettini = 'Zverev VS Berrettini RR'\n","\n","Medvedev and Zverev = 'Medvedev VS Zverev RR'\n","\n","Sinner and Hurkacz = 'Sinner VS Hurkacz RR'\n","\n","Zverev and Hurkacz = 'Zverev VS Hurkacz RR'\n","\n","Medvedev and Sinner = 'Medvedev VS Sinner RR'\n","\n","Djokovic and Zverev = 'Djokovic VS Zverev SF' # SF is Semi-Final\n","\n","Medvedev and Ruud = 'Medvedev VS Ruud SF'\n","\n","Medvedev and Zverev = 'Medvedev VS Zverev F' #F is Final"]},{"cell_type":"code","metadata":{"id":"VBED0apaGu6Y"},"source":["# inizio definendo per ogni topic le cose che deve contenere\n","Medvedev = ['Medvedev', '#Medvedev', '@DaniilMedwed']\n","Zverev = ['Zverev', '#Zverev', '@AlexZverev']\n","Berrettini = ['Berrettini', '#Berrettini', '@MattBerrettini']\n","Hurkacz = ['Hurkacz', '#Hurkacz', '@HubertHurkacz']\n","Sinner = ['Sinner', '#Sinner', '@janniksin']\n","Djokovic = ['Djokovic', '#Djokovic', '@DjokerNole']\n","Tsitsipas = ['Tsitsipas', '#Tsitsipas', '@steftsitsipas']\n","Rublev = ['Rublev', '#Rublev', '@AndreyRublev97']\n","Ruud = ['Ruud', '#Ruud', '@CasperRuud98']\n","Norrie = ['Norrie', '#Norrie', '@cam_norrie']\n","ATP_Finals = ['NittoATPFinals', 'TennisTakesOverTorino', '#ATPFinals', 'ATPFinals']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvxyovaMG4mt"},"source":["# creo le colonne con valori 1 e 0\n","df['Medvedev'] = np.where(df['text'].str.contains('|'.join(Medvedev)), 1, 0)\n","df['Zverev'] = np.where(df['text'].str.contains('|'.join(Zverev)), 1, 0)\n","df['Berrettini'] = np.where(df['text'].str.contains('|'.join(Berrettini)), 1, 0)\n","df['Hurkacz'] = np.where(df['text'].str.contains('|'.join(Hurkacz)), 1, 0)\n","df['Sinner'] = np.where(df['text'].str.contains('|'.join(Sinner)), 1, 0)\n","df['Djokovic'] = np.where(df['text'].str.contains('|'.join(Djokovic)), 1, 0)\n","df['Tsitsipas'] = np.where(df['text'].str.contains('|'.join(Tsitsipas)), 1, 0)\n","df['Rublev'] = np.where(df['text'].str.contains('|'.join(Rublev)), 1, 0)\n","df['Ruud'] = np.where(df['text'].str.contains('|'.join(Ruud)), 1, 0)\n","df['Norrie'] = np.where(df['text'].str.contains('|'.join(Norrie)), 1, 0)\n","df['ATP_Finals'] = np.where(df['text'].str.contains('|'.join(ATP_Finals)), 1, 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kslw-1eGb-vA"},"source":["df_topic = df[[\"ATP_Finals\", \"Sinner\", \"Norrie\", \"Ruud\", \"Rublev\", \"Tsitsipas\", \"Medvedev\", \"Zverev\", \"Berrettini\", \"Hurkacz\", \"Djokovic\"]]\n","df_topic_NO_ATP = df[[\"Sinner\", \"Norrie\", \"Ruud\", \"Rublev\", \"Tsitsipas\", \"Medvedev\", \"Zverev\", \"Berrettini\", \"Hurkacz\", \"Djokovic\"]]\n","\n","df['topic'] = df_topic_NO_ATP.apply(lambda row: row[row == 1].index.values, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mZFCMuUSHQQJ"},"source":["# df = df.drop(['ATP_Finals', 'Norrie', 'Ruud', 'Medvedev', 'Zverev', 'Berrettini', 'Hurkacz', 'Sinner', 'Djokovic', 'Tsitsipas', 'Rublev'], axis=1)\n","df.to_csv(f'{st_man_root_dir}twitter_text_cleaned_lang_and_player_det.csv', index=False, sep=',', encoding='utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8oLG98lYKzp2"},"source":["df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QNdCXf22K339"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3Qh84sZh0mF"},"source":["df.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hFJ6CFfmyuFg"},"source":["# per staging Marco 2 subset: it e en\n","df_en = df[df[\"text_lang\"].str.contains(\"English\")]\n","df_it = df[df[\"text_lang\"].str.contains(\"Italian\")]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DgObNqufy9Qu"},"source":["print(df_en.shape)\n","print(df_it.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SciViZB_zFcW"},"source":["df_en.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QAJWWefhzGPZ"},"source":["df_it.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N7l9EhhfzG4U"},"source":["df_en.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HUP6DqotzHVk"},"source":["df_it.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2I_IheA0y1Ur"},"source":["# to stagin Ant M.\n","df_en.to_csv(f'{st_man_root_dir}twitter_text_cleaned_lang_and_player_det_EN.csv', index=False, sep=',', encoding='utf-8')\n","df_it.to_csv(f'{st_man_root_dir}twitter_text_cleaned_lang_and_player_det_IT.csv', index=False, sep=',', encoding='utf-8')\n","\n","# to staging Marco\n","df_en.to_csv(f'{st_marco_root_dir}twitter_text_cleaned_lang_and_player_det_EN.csv', index=False, sep=',', encoding='utf-8')\n","df_it.to_csv(f'{st_marco_root_dir}twitter_text_cleaned_lang_and_player_det_IT.csv', index=False, sep=',', encoding='utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oD4XSMCGGAui"},"source":["## Labeling"]},{"cell_type":"code","metadata":{"id":"UYWzwAy-8GN6"},"source":["# creare prima il subset che interessa e lo salvo per salvare il seme\n","# una volta fatto commentare queste celle\n","# ATTENZIONE già fatto, lasciare commentate!\n","\n","# df = pd.read_csv(f'{st_man_root_dir}twitter_text_cleaned_lang_and_player_det_IT.csv')\n","# df_label = df.sample(n=2000) #frac=0.7\n","# df_label.to_csv(f'{st_man_root_dir}sample_2000_for_labeling_IT.csv', index=False, sep=',', encoding='utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I5JCGtEjvBx6"},"source":["# riprendo da qui il sample generato sopra\n","df_label = pd.read_csv(f'{st_man_root_dir}sample_2000_for_labeling_IT.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSRs-beA8VSC"},"source":["df_label.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxsES11_GAIl"},"source":["# divido il df in pezzi da 100 e procedo in ordine\n","label_100 = df_label.iloc[:100,:] # fatto\n","label_200 = df_label.iloc[100:200,:] # fatto\n","label_300 = df_label.iloc[200:300,:] # fatto\n","label_400 = df_label.iloc[300:400,:] # fatto\n","label_500 = df_label.iloc[400:500,:] # fatto\n","label_600 = df_label.iloc[500:600,:] # fatto\n","label_700 = df_label.iloc[600:700,:] # fatto\n","label_800 = df_label.iloc[700:800,:] # fatto\n","label_900 = df_label.iloc[800:900,:] # fatto\n","label_1000 = df_label.iloc[900:1000,:] # fatto\n","label_1100 = df_label.iloc[1000:1100,:] # fatto\n","label_1200 = df_label.iloc[1100:1200,:]\n","label_1300 = df_label.iloc[1200:1300,:]\n","label_1400 = df_label.iloc[1300:1400,:]\n","label_1500 = df_label.iloc[1400:1500,:]\n","label_1600 = df_label.iloc[1500:1600,:]\n","label_1700 = df_label.iloc[1600:1700,:]\n","label_1800 = df_label.iloc[1700:1800,:]\n","label_1900 = df_label.iloc[1800:1900,:]\n","label_2000 = df_label.iloc[1900:2000,:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqy6pyyuzAO2"},"source":["# creo una lista vuota\n","sentiment = []\n","count = 1\n","# cambiare label_ ad ogni giro (1 occorrenza)\n","for b in tqdm(label_1100.text_nonl_hash_men_http_num):\n","  print()\n","  print(count)\n","  print(b)\n","  add_sent = input('1=pos, 0=neg, 2=neu: ')\n","  add_sent = add_sent.strip(' ')\n","  sentiment.append(add_sent)\n","  count += 1\n","\n","# cambiare label_ ad ogni giro (1 occorrenza)\n","label_1100['sentiment'] = sentiment"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UuXwSK33zvve"},"source":["# cambiare label_ ad ogni giro (2 occorrenze)\n","label_1100.to_csv(f'{st_man_root_dir}label_1100_IT.csv', index=False, sep=',', encoding='utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EH4rAzWA7Wdm"},"source":["# merge di tutti i label fatti\n","\n","path = st_man_root_dir\n","\n","all_files = glob.glob(os.path.join(path, \"label_*.csv\"))\n","df_from_each_file = (pd.read_csv(f, sep=',') for f in all_files)\n","df_merged = pd.concat(df_from_each_file, ignore_index=True)\n","\n","# per sicurezza\n","df_merged.drop_duplicates(subset=['id'], inplace=True, ignore_index=False)\n","df_merged.dropna(subset=['sentiment'], inplace=True)\n","\n","df_merged.to_csv(f'{st_tone_root_dir}label_IT.csv', index=False, sep=',', encoding='utf-8')\n","df_merged.to_csv(f'{st_natalia_root_dir}label_IT.csv', index=False, sep=',', encoding='utf-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hG1vbcQK_iqZ"},"source":["df_merged.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KguEH3K3_oOd"},"source":["df_merged.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zp0yTARn_pk5"},"source":["df_merged.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TcwnFQNa-t_K"},"source":["# 5. Sentiment\n","MARCO"]},{"cell_type":"code","metadata":{"id":"GXEg0QEgvgsH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637680991933,"user_tz":-60,"elapsed":2761,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"a98e710b-3e4f-4bec-93c8-479ac802cf2d"},"source":["pip install vaderSentiment"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting vaderSentiment\n","  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n","\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81 kB 13.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 15.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n","Installing collected packages: vaderSentiment\n","Successfully installed vaderSentiment-3.3.2\n"]}]},{"cell_type":"markdown","metadata":{"id":"IR1xGcpw-rkE"},"source":["## Importo Dataset"]},{"cell_type":"code","metadata":{"id":"nSazrmk4dJA9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637690963601,"user_tz":-60,"elapsed":1051,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"cc801cfb-578c-42d4-9098-4ee98fcb8aed"},"source":["import pandas as pd\n","dfen = pd.read_csv('/content/drive/MyDrive/nucleare/STAGING_MARCO/Twitter_Manenti_Files/twitter_text_cleaned_lang_and_player_det_EN.csv')\n","dfen.shape"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(49252, 36)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_IswGJZK_Qow","executionInfo":{"status":"ok","timestamp":1637690999946,"user_tz":-60,"elapsed":1027,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"9f0331d4-6cf3-41c7-d083-6dd7cb704f7f"},"source":["dfit = pd.read_csv('/content/drive/MyDrive/nucleare/STAGING_MARCO/Twitter_Manenti_Files/twitter_text_cleaned_lang_and_player_det_IT.csv')\n","dfit.shape"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(15985, 36)"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"BiPHu9K8_k4_"},"source":["## Vader En"]},{"cell_type":"code","metadata":{"id":"m4VeaYVgdFHL","executionInfo":{"status":"ok","timestamp":1637691375800,"user_tz":-60,"elapsed":7534,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}}},"source":["from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","\n","\n","vader=[]\n","\n","analyzer = SentimentIntensityAnalyzer()\n","\n","for x in (dfen.loc[:,'text_nonl_hash_men_http_num']):\n","  a = analyzer.polarity_scores(x)\n","  vader.append(a)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"5rJaCP_adKPf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637691397674,"user_tz":-60,"elapsed":219,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"a6718d34-372c-4442-e488-303bf565963e"},"source":["df2 = pd.DataFrame(vader)\n","df2.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(49252, 4)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"VpEWYanodXwe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637691441799,"user_tz":-60,"elapsed":212,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"6f7e7a0f-764b-415d-dec7-4260efa75582"},"source":["print(df2)\n","df2.to_csv('/content/drive/MyDrive/nucleare/STAGING_MARCO/Vader_en.csv')"],"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["         neg    neu    pos  compound\n","0      0.145  0.681  0.174    0.1759\n","1      0.104  0.563  0.333    0.7430\n","2      0.000  1.000  0.000    0.0000\n","3      0.104  0.563  0.333    0.7430\n","4      0.145  0.681  0.174    0.1759\n","...      ...    ...    ...       ...\n","49247  0.000  0.740  0.260    0.6784\n","49248  0.000  1.000  0.000    0.0000\n","49249  0.062  0.684  0.254    0.7845\n","49250  0.000  1.000  0.000    0.0000\n","49251  0.320  0.680  0.000   -0.5093\n","\n","[49252 rows x 4 columns]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172},"id":"mmqa22zNAP1Q","executionInfo":{"status":"ok","timestamp":1637693698535,"user_tz":-60,"elapsed":250,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"83c4a5ba-2c4f-41cf-ae77-1d5096bf9e6f"},"source":["df2 = pd.read_csv('/content/drive/MyDrive/nucleare/STAGING_MARCO/Vader_en.csv')\n","df2.head(4)"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>neg</th>\n","      <th>neu</th>\n","      <th>pos</th>\n","      <th>compound</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.145</td>\n","      <td>0.681</td>\n","      <td>0.174</td>\n","      <td>0.1759</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.104</td>\n","      <td>0.563</td>\n","      <td>0.333</td>\n","      <td>0.7430</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.000</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.104</td>\n","      <td>0.563</td>\n","      <td>0.333</td>\n","      <td>0.7430</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0    neg    neu    pos  compound\n","0           0  0.145  0.681  0.174    0.1759\n","1           1  0.104  0.563  0.333    0.7430\n","2           2  0.000  1.000  0.000    0.0000\n","3           3  0.104  0.563  0.333    0.7430"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"MOw3XbLWAJoG"},"source":["## MERGE -- csv_tradotti"]},{"cell_type":"code","metadata":{"id":"b-VMdKtiZCEA","executionInfo":{"status":"ok","timestamp":1637691623053,"user_tz":-60,"elapsed":211,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}}},"source":["import os\n","import glob\n","import pandas as pd\n","os.chdir(\"/content/drive/MyDrive/nucleare/STAGING_MARCO/PYTHON_TRADOTTI\")"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8F7lwP3ZIPU","colab":{"base_uri":"https://localhost:8080/","height":80},"executionInfo":{"status":"ok","timestamp":1637691605932,"user_tz":-60,"elapsed":960,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"9b8f9e18-f0d4-42e4-a7ba-f34568178327"},"source":["extension = 'csv'\n","all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n","\n","#combine all files in the list\n","combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n","#export to csv\n","combined_csv.to_csv( \"combined_csv.csv\", index=False, encoding='utf-8-sig')\n","\n","df1 = pd.read_csv('/content/drive/MyDrive/nucleare/STAGING_MARCO/PYTHON_TRADOTTI/combined_csv.csv')\n","df1.head(1)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_nonl_hash_men_http_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>We never wanted to see you like this, Matthew 💔 you're great, you'll be stronger than before🎾 | |</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                          text_nonl_hash_men_http_num\n","0  We never wanted to see you like this, Matthew 💔 you're great, you'll be stronger than before🎾 | | "]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"KwSmSJ9oBL6e"},"source":["## Vader it"]},{"cell_type":"code","metadata":{"id":"BxmPTB85Zu74","executionInfo":{"status":"ok","timestamp":1637691676049,"user_tz":-60,"elapsed":3165,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}}},"source":["from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","\n","\n","vader=[]\n","\n","analyzer = SentimentIntensityAnalyzer()\n","\n","for x in (df1.loc[:,'text_nonl_hash_men_http_num']):\n","  a = analyzer.polarity_scores(x)\n","  vader.append(a)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qadwki-WZ0ED","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637691677935,"user_tz":-60,"elapsed":619,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"2eeabd3d-6896-4d99-8542-b68b574a9942"},"source":["df1 = pd.DataFrame(vader)\n","df1.shape"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 4)"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"bQOHXCZJZ3eg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637691680021,"user_tz":-60,"elapsed":602,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"7d916eef-16d5-4c08-fb2e-2f8b149ab45b"},"source":["print(df1)\n","df1.to_csv('/content/drive/MyDrive/nucleare/STAGING_MARCO/Vader_it.csv')"],"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["        neg    neu    pos  compound\n","0     0.095  0.492  0.412    0.8834\n","1     0.000  1.000  0.000    0.0000\n","2     0.000  1.000  0.000    0.0000\n","3     0.262  0.738  0.000   -0.4926\n","4     0.000  0.909  0.091    0.4588\n","...     ...    ...    ...       ...\n","9995  0.090  0.910  0.000   -0.4847\n","9996  0.000  1.000  0.000    0.0000\n","9997  0.274  0.726  0.000   -0.6007\n","9998  0.091  0.909  0.000   -0.2960\n","9999  0.059  0.722  0.219    0.7424\n","\n","[10000 rows x 4 columns]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":172},"id":"cBSv3WSQCCMQ","executionInfo":{"status":"ok","timestamp":1637693668638,"user_tz":-60,"elapsed":311,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"6f1eb932-73eb-44ba-ccc7-acc22ee6e5d9"},"source":["df1 = pd.read_csv('/content/drive/MyDrive/nucleare/STAGING_MARCO/Vader_it.csv')\n","df1.head(4)"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>neg</th>\n","      <th>neu</th>\n","      <th>pos</th>\n","      <th>compound</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.095</td>\n","      <td>0.492</td>\n","      <td>0.412</td>\n","      <td>0.8834</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.000</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.000</td>\n","      <td>1.000</td>\n","      <td>0.000</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.262</td>\n","      <td>0.738</td>\n","      <td>0.000</td>\n","      <td>-0.4926</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0    neg    neu    pos  compound\n","0           0  0.095  0.492  0.412    0.8834\n","1           1  0.000  1.000  0.000    0.0000\n","2           2  0.000  1.000  0.000    0.0000\n","3           3  0.262  0.738  0.000   -0.4926"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"6Pqa5nR1C4_O"},"source":["## MERGE DATASET "]},{"cell_type":"code","metadata":{"id":"tDUYZ5xUCv0G","executionInfo":{"status":"ok","timestamp":1637691980327,"user_tz":-60,"elapsed":296,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}}},"source":["result_merge_it = pd.concat([dfit, df1], axis=1).reindex(dfit.index)\n","result_merge_it.head(1)\n","result_merge_it.shape"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8cdtSLsDIlf","executionInfo":{"status":"ok","timestamp":1637692031627,"user_tz":-60,"elapsed":1510,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}}},"source":["result_merge_it.to_csv('/content/drive/MyDrive/nucleare/STAGING_MARCO/vader_merge_it.csv')"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aKjqBVoVDT-p","executionInfo":{"status":"ok","timestamp":1637692083608,"user_tz":-60,"elapsed":225,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"b83cfc8a-c806-40b9-bda8-4c0817c35ace"},"source":["result_merge_en = pd.concat([dfen, df2], axis=1).reindex(dfen.index)\n","result_merge_en.head(1)\n","result_merge_en.shape"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(49252, 41)"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"_Um14VsADqDs","executionInfo":{"status":"ok","timestamp":1637692149341,"user_tz":-60,"elapsed":3216,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}}},"source":["result_merge_en.to_csv('/content/drive/MyDrive/nucleare/STAGING_MARCO/vader_merge_en.csv')"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZZZ_V0-CDwML","executionInfo":{"status":"ok","timestamp":1637693008784,"user_tz":-60,"elapsed":342,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"d49d90eb-8cdd-487f-f98e-d5c5623abd3f"},"source":["prot_new_dataset = result_merge_it.append(result_merge_en)\n","prot_new_dataset.shape"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(65237, 41)"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"id":"h9M16La0GsgR","executionInfo":{"status":"ok","timestamp":1637693015593,"user_tz":-60,"elapsed":3713,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}}},"source":["prot_new_dataset.to_csv('/content/drive/MyDrive/nucleare/STAGING_MARCO/new_dataset.csv')"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"2Y6s00qtHMok","executionInfo":{"status":"ok","timestamp":1637693063845,"user_tz":-60,"elapsed":330,"user":{"displayName":"Marco Ciuffetelli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07834613511777058165"}},"outputId":"3e431015-bb98-4738-99cf-56dc705e4e3b"},"source":["prot_new_dataset.head(1)"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>user</th>\n","      <th>date</th>\n","      <th>text</th>\n","      <th>favorite_count</th>\n","      <th>hashtags</th>\n","      <th>location</th>\n","      <th>retweet</th>\n","      <th>retweet_count</th>\n","      <th>followers_count</th>\n","      <th>in_reply_to_status_id</th>\n","      <th>user_mentions</th>\n","      <th>date_norm</th>\n","      <th>time_zone</th>\n","      <th>text_nonl</th>\n","      <th>text_nonl_hash</th>\n","      <th>text_nonl_hash_men</th>\n","      <th>text_nonl_hash_men_http</th>\n","      <th>text_nonl_hash_men_http_num</th>\n","      <th>text_nonl_hash_men_http_num_simb</th>\n","      <th>text_lang</th>\n","      <th>text_lan_code</th>\n","      <th>lang_confidence</th>\n","      <th>prediction_reliable</th>\n","      <th>Medvedev</th>\n","      <th>Zverev</th>\n","      <th>Berrettini</th>\n","      <th>Hurkacz</th>\n","      <th>Sinner</th>\n","      <th>Djokovic</th>\n","      <th>Tsitsipas</th>\n","      <th>Rublev</th>\n","      <th>Ruud</th>\n","      <th>Norrie</th>\n","      <th>ATP_Finals</th>\n","      <th>topic</th>\n","      <th>Unnamed: 0</th>\n","      <th>neg</th>\n","      <th>neu</th>\n","      <th>pos</th>\n","      <th>compound</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1460367628070014991</td>\n","      <td>MaricieloCuore</td>\n","      <td>Mon Nov 15 22:02:29 +0000 2021</td>\n","      <td>Non avremmo mai voluto vederti così, Matteo 💔\\n\\nSei grande, tornerai più forte di prima 💪🎾\\n\\n#Berrettini | #NittoATPFinals | #EurosportTENNIS https://t.co/vj9Zv7tlQm</td>\n","      <td>0</td>\n","      <td>['Berrettini', 'NittoATPFinals']</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","      <td>60</td>\n","      <td>45</td>\n","      <td>NaN</td>\n","      <td>['Eurosport_IT']</td>\n","      <td>2021-11-15 22:02:29</td>\n","      <td>z+0000</td>\n","      <td>Non avremmo mai voluto vederti così, Matteo 💔  Sei grande, tornerai più forte di prima 💪🎾  #Berrettini | #NittoATPFinals | #EurosportTENNIS https://t.co/vj9Zv7tlQm</td>\n","      <td>Non avremmo mai voluto vederti così, Matteo 💔 Sei grande, tornerai più forte di prima 💪🎾 | | https://t.co/vj9Zv7tlQm</td>\n","      <td>Non avremmo mai voluto vederti così, Matteo 💔 Sei grande, tornerai più forte di prima 💪🎾 | | https://t.co/vj9Zv7tlQm</td>\n","      <td>Non avremmo mai voluto vederti così, Matteo 💔 Sei grande, tornerai più forte di prima 💪🎾 | |</td>\n","      <td>Non avremmo mai voluto vederti così, Matteo 💔 Sei grande, tornerai più forte di prima 💪🎾 | |</td>\n","      <td>Non avremmo mai voluto vederti così Matteo Sei grande tornerai più forte di prima</td>\n","      <td>Italian</td>\n","      <td>it</td>\n","      <td>98.0</td>\n","      <td>True</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>['Berrettini']</td>\n","      <td>0.0</td>\n","      <td>0.095</td>\n","      <td>0.492</td>\n","      <td>0.412</td>\n","      <td>0.8834</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    id            user  ...    pos compound\n","0  1460367628070014991  MaricieloCuore  ...  0.412   0.8834\n","\n","[1 rows x 41 columns]"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"VVdTk8UXxPkN"},"source":["# 6. BoW\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UfFzJp30Yp6r"},"source":["## 6.1 preprocessing our dataset: lematizzation, stopwords, ngrams"]},{"cell_type":"code","metadata":{"id":"e2oGKuQdxPkT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637672050052,"user_tz":-60,"elapsed":624,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"b14650e7-0b4f-4088-8327-948364af4463"},"source":["import nltk ### libreria di linguistica (Stanford)\n","from nltk.stem import WordNetLemmatizer #### individua la radice linguistica delle parole: non tronca le parole come un stamming\n","nltk.download('wordnet') ## tassonomia lingua inglese\n","nltk.download('stopwords')\n","\n","import warnings\n","from tqdm import tqdm\n","from pprint import pprint\n","from gensim.models.phrases import Phrases\n","from nltk.corpus import stopwords\n","pd.set_option('display.max_colwidth', None)\n","\n","connectors = stopwords.words('english')\n","stop = stopwords.words('english')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","metadata":{"id":"p3rLfDa3ArAt"},"source":["file_path = output_root_dir +'twitter_text_cleaned_lang_topic_det.csv'\n","df = pd.read_csv(file_path, encoding='utf-8')\n","df['text_cleaned'] = df['text_nonl_hash_men_http_num_simb']\n","print(df.isna().sum())\n","print(df.info())\n","print(df.columns)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_pdWM2QkA4hc"},"source":["df = df[['id', 'user', 'date', 'text', 'text_cleaned','text_lan_code', 'lang_confidence', 'prediction_reliable', 'topic']]\n","print(df.isna().sum())\n","df.info()\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QtkYQ0dK6lhp"},"source":["print(f'original len: {len(df)}')\n","\n","dff = df[df['text_lan_code'].isin(['en'])]\n","eng_len = len(dff)\n","print(f'english len: {eng_len}')\n","\n","dff = dff[dff['prediction_reliable'] == True]\n","dff = dff[dff['lang_confidence'] > 96]\n","\n","print(f'filtered len: {len(dff)}')\n","print(f'loss: {eng_len - len(dff)}')\n","\n","print(dff.isna().sum())\n","print(dff.groupby(['text_lan_code', 'prediction_reliable']).size())\n","print(dff.groupby(['text_lan_code', 'lang_confidence']).size())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L5Ykdc_uxPkU"},"source":["df = dff.copy()\n","\n","lemmatizer = WordNetLemmatizer()\n","df['text_cleaned'] = df['text_cleaned'].str.lower().str.replace('[^\\w\\s]',' ', regex=True) #type(text) series of string\n","df['text_cleaned'] = df['text_cleaned'].str.lower().str.replace('\\s+', ' ', regex=True) ## rimuovi spazi multipli\n","\n","raw_text = df[~df['text_cleaned'].isna()]['text_cleaned']\n","\n","print(len(raw_text))\n","\n","####pulizia: sostituisco tutti i caratteri speciali con uno spazio\n","text = raw_text.str.lower()\n","print(len(text))\n","print(text.head())\n","\n","###TOKENIZATION\n","df['token'] = text.str.split() ##text: series of list, text[0] list of string, text[0][0] string \n","\n","###LEMMATIZATION\n","df['ltoken'] = df.token.apply(lambda x: [lemmatizer.lemmatize(sent) for sent in x]) #text: series of list, text[0] list of string (lemmatized), text[0][0] string\n","\n","# print(f'text[0][0]-({type(df.ltoken[0][0])})')\n","# print(f'text[0]-({type(df.ltoken[0])})')\n","# print(f'text-({type(df.ltoken)})')\n","\n","print(f'text_cleaned: {df.text_cleaned[0]}')\n","print(f'token       : {df.token[0]}')\n","print(f'ltoken      : {df.ltoken[0]}')\n","\n","# stop.extend(['good', 'bad', 'dont', 'many', 'love', 'excellent', 'would', 'perfect', 'even', 'great','nice', 'amazing'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ix4tTrNEFTt2"},"source":["number = 1\n","print(f'text_cleaned: {df.text_cleaned.to_list()[number]}')\n","print(f'token       : {df.token.to_list()[number]}')\n","print(f'ltoken      : {df.ltoken.to_list()[number]}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UCRsvA9eFynK"},"source":["print(df.isna().sum())\n","len_target = 1\n","field_name ='token' \n","counter = df[df[field_name].str.len() < len_target ][field_name].count()\n","print(f'{field_name} with len < {len_target}: {counter}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kuWZ87umDwBy"},"source":["my_stop_words = []\n","stop.extend(my_stop_words)\n","\n","df['ltoken'] = df.ltoken.apply(lambda row: [item for item in row if item not in stop])\n","\n","df['stopwords'] = df.ltoken.apply(lambda row: [item for item in row if item in stop])\n","df['nostopwords'] = df.ltoken.apply(lambda row: [item for item in row if item not in stop])\n","\n","bigram  = Phrases(df.ltoken, min_count=5, threshold=0.2, common_terms=connectors) #gensim 3, ad esempio \"and\" \n","df['bigrams_afternostop'] = df.ltoken.apply(lambda row: bigram[row])\n","\n","ngram   = Phrases(df.bigrams_afternostop, min_count=5, threshold=0.2, common_terms=connectors) # gensim 3\n","df['ngrams_afternostop'] = df.bigrams_afternostop.apply(lambda row: ngram[row])\n","\n","df.bigrams_afternostop = df.bigrams_afternostop.apply(lambda bigr: [item for item in bigr if item not in stop])\n","df.ngrams_afternostop = df.ngrams_afternostop.apply(lambda ngr: [item for item in ngr if item not in stop])\n","\n","bigram  = Phrases(df.nostopwords, min_count=5, threshold=0.2, common_terms=connectors) #gensim 3, ad esempio \"and\" \n","df['bigrams_beforenostop'] = df.nostopwords.apply(lambda row: bigram[row])\n","\n","ngram   = Phrases(df.bigrams_beforenostop, min_count=5, threshold=0.2, common_terms=connectors) # gensim 3\n","df['ngrams_beforenostop'] = df.bigrams_beforenostop.apply(lambda row: ngram[row])\n","\n","df['bigrams_afternostop_sent'] = df.bigrams_afternostop.apply(lambda row: ' '.join(row))\n","df['bigrams_beforenostop_sent'] = df.bigrams_beforenostop.apply(lambda row: ' '.join(row))\n","df['ngrams_afternostop_sent'] = df.ngrams_afternostop.apply(lambda row: ' '.join(row))\n","df['ngrams_beforenostop_sent'] = df.ngrams_beforenostop.apply(lambda row: ' '.join(row))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5xTAXVZfIJ6W"},"source":["# print(df.isna().sum())\n","len_target = 1\n","# 'bigrams_afternostop_sent' \n","# 'bigrams_beforenostop_sent'\n","# 'ngrams_afternostop_sent'  \n","# 'ngrams_beforenostop_sent' \n","field_name ='ngrams_beforenostop_sent' \n","counter = df[df[field_name].str.len() < len_target ][field_name].count()\n","print(f'{field_name} with len < {len_target}: {counter}')\n","\n","n = 10\n","print(f'df.bigrams_afternostop_sent[{n}] : {df.bigrams_afternostop_sent.to_list()[n]}')\n","print(f'df.bigrams_beforenostop_sent[{n}]: {df.bigrams_beforenostop_sent.to_list()[n]}')\n","print(f'df.ngrams_afternostop_sent[{n}]  : {df.ngrams_afternostop_sent.to_list()[n]}')\n","print(f'df.ngrams_beforenostop_sent[{n}] : {df.ngrams_beforenostop_sent.to_list()[n]}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O6DbE5TmJG0N"},"source":["df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tznsaSoSrrWi"},"source":["### 6.1.1 Saving"]},{"cell_type":"code","metadata":{"id":"GYE_PmU-rxVD"},"source":["df_saving = df.copy() #.replace('\\n','', regex=True)\n","df_saving = df_saving[['id', 'user', 'date', 'text', 'text_cleaned','text_lan_code', 'lang_confidence', 'prediction_reliable', 'topic',\n","       'bigrams_afternostop_sent', 'bigrams_beforenostop_sent',\n","       'ngrams_afternostop_sent', 'ngrams_beforenostop_sent']]\n","saving_file_name = f'{sentiment_root_dir}ngrams_ourdataset_dataframe.csv'\n","df_saving.to_csv(saving_file_name, index=False, encoding='utf-8', sep =',' )\n","df_saving.isna().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O5CCk-khY2az"},"source":["## 6.2 Preprocesing labelled dataset"]},{"cell_type":"code","metadata":{"id":"56OEm9zl3ZDq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637672116484,"user_tz":-60,"elapsed":284,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"508e9e76-5634-42ec-e4f8-5e68ae523d0c"},"source":["pd.set_option('display.max_colwidth', None)\n","file_path = st_tone_root_dir +'label_IT.csv'\n","df_open_label = pd.read_csv(file_path)\n","len(df_open_label)\n","df_open_label.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['id', 'user', 'date', 'text', 'favorite_count', 'hashtags', 'location',\n","       'retweet', 'retweet_count', 'followers_count', 'in_reply_to_status_id',\n","       'user_mentions', 'date_norm', 'time_zone', 'text_nonl',\n","       'text_nonl_hash', 'text_nonl_hash_men', 'text_nonl_hash_men_http',\n","       'text_nonl_hash_men_http_num', 'text_nonl_hash_men_http_num_simb',\n","       'text_lang', 'text_lan_code', 'lang_confidence', 'prediction_reliable',\n","       'Medvedev', 'Zverev', 'Berrettini', 'Hurkacz', 'Sinner', 'Djokovic',\n","       'Tsitsipas', 'Rublev', 'Ruud', 'Norrie', 'ATP_Finals', 'topic',\n","       'sentiment'],\n","      dtype='object')"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1TOtTMyE0XOM","executionInfo":{"status":"ok","timestamp":1637672120712,"user_tz":-60,"elapsed":280,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"6aef03b2-d65b-4683-ef24-9db5dcf6ee68"},"source":["df_open_label.groupby(['lang_confidence']).size()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["lang_confidence\n","50.0      3\n","60.0      1\n","64.0      3\n","80.0      1\n","85.0      1\n","87.0     22\n","92.0      6\n","93.0      3\n","94.0      7\n","95.0     30\n","96.0    109\n","97.0     92\n","98.0    283\n","99.0    531\n","dtype: int64"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"ogYd7hK94JmL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637672125601,"user_tz":-60,"elapsed":245,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"aa0b8444-8e6a-46d7-8b7a-85405e328b44"},"source":["df_label = df_open_label.copy()\n","print(df_label.groupby('sentiment').size())\n","df_label.sentiment = df_label.sentiment.astype('int')\n","print(len(df_label))\n","df_label = df_label[df_label.sentiment < 2]\n","print(len(df_label))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sentiment\n","0.0     27\n","1.0    284\n","2.0    781\n","dtype: int64\n","1092\n","311\n"]}]},{"cell_type":"code","metadata":{"id":"5nPxvMUMBie1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637672131713,"user_tz":-60,"elapsed":249,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"8912bb68-a723-4dc0-cc53-445f922ba8eb"},"source":["import nltk ### libreria di linguistica (Stanford)\n","nltk.download('wordnet') ## tassonomia lingua inglese\n","\n","from tqdm import tqdm\n","from nltk.stem import WordNetLemmatizer #### individua la radice linguistica delle parole: non tronca le parole come un stamming\n","lemmatizer = WordNetLemmatizer()\n","\n","raw_text = df_label[~df_label['text_nonl_hash_men_http_num'].isna()].loc[:, 'text_nonl_hash_men_http_num']\n","print(len(raw_text))\n","\n","####pulizia: sostituisco tutti i caratteri speciali con uno spazio\n","text = raw_text.str.lower().str.replace('[^\\w\\s]',' ', regex=True) #type(text) series of string\n","text = text.str.lower().str.replace('\\s+', ' ', regex=True) ## rimuovi spazi multipli\n","# text = raw_text.str.replace('!\"%&()?^,.-;:_', ' ', regex=False) ## rimuovi spazi multipli\n","print(len(text))\n","\n","# ##TOKENIZATION\n","df_label['token'] = text.str.split() ##text: series of list, text[0] list of string, text[0][0] string\n","\n","# ###LEMMATIZATION\n","df_label['ltoken'] = df_label.token.apply(lambda x: [lemmatizer.lemmatize(sent) for sent in x]) #text: series of list, text[0] list of string (lemmatized), text[0][0] string\n","\n","print(f'text[0][0]-({type(df_label.token[3][0])})')\n","print(f'text[0]-({type(df_label.token[3])})')\n","print(f'text-({type(df_label.token)})')\n","print(f'text[0][0]-({(df_label.token[3][0])})')\n","print(f'text[0]-({(df_label.token[3])})')\n","# print(f'text-({(df.token)})')\n","print(df_label.isna().sum())\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","311\n","311\n","text[0][0]-(<class 'str'>)\n","text[0]-(<class 'list'>)\n","text-(<class 'pandas.core.series.Series'>)\n","text[0][0]-(zverev)\n","text[0]-(['zverev', 'mi', 'è', 'sempre', 'piaciuto', 'dopo', 'questo', 'gesto', 'ancora', 'di', 'più'])\n","id                                    0\n","user                                  0\n","date                                  0\n","text                                  0\n","favorite_count                        0\n","hashtags                              0\n","location                            140\n","retweet                               0\n","retweet_count                         0\n","followers_count                       0\n","in_reply_to_status_id               294\n","user_mentions                         0\n","date_norm                             0\n","time_zone                             0\n","text_nonl                             0\n","text_nonl_hash                        0\n","text_nonl_hash_men                    0\n","text_nonl_hash_men_http               0\n","text_nonl_hash_men_http_num           0\n","text_nonl_hash_men_http_num_simb      0\n","text_lang                             0\n","text_lan_code                         0\n","lang_confidence                       0\n","prediction_reliable                   0\n","Medvedev                              0\n","Zverev                                0\n","Berrettini                            0\n","Hurkacz                               0\n","Sinner                                0\n","Djokovic                              0\n","Tsitsipas                             0\n","Rublev                                0\n","Ruud                                  0\n","Norrie                                0\n","ATP_Finals                            0\n","topic                                 0\n","sentiment                             0\n","token                                 0\n","ltoken                                0\n","dtype: int64\n"]}]},{"cell_type":"code","metadata":{"id":"1icd1qUqEISr"},"source":["stop.extend(['good', 'bad', 'dont', 'many', 'love', 'excellent', 'would', 'perfect', 'even', 'great','nice', 'amazing'])\n","my_stop_words = []\n","\n","stop.extend(my_stop_words)\n","\n","df_label['ltoken'] = df_label.ltoken.apply(lambda row: [item for item in row if item not in stop])\n","\n","# df['stopwords'] = df.ltoken.apply(lambda row: [item for item in row if item in stop])\n","# df['nostopwords'] = df.ltoken.apply(lambda row: [item for item in row if item not in stop])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"juIfC1ZwHUcn","executionInfo":{"status":"ok","timestamp":1637672143334,"user_tz":-60,"elapsed":287,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"29417d3f-b6f9-40fa-bb48-cf37cb118b60"},"source":["df_label['ltoken']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1                                                                                                                                                                                                         [zverev, mi, è, sempre, piaciuto, dopo, questo, gesto, ancora, di, più]\n","3                                                                                                                                                                                                         [zverev, mi, è, sempre, piaciuto, dopo, questo, gesto, ancora, di, più]\n","4                                                                                                                                                                                                                                     [lo, sport, dovrebbe, essere, sempre, così]\n","5                                                                                                                                                                                                                 [due, su, tre, sul, veloce, è, un, dio, solo, lo, può, fermare]\n","7                                                                                                                                                                                                                           [un, signore, che, ci, sta, prendendo, per, il, culo]\n","                                                                                                                                          ...                                                                                                                                    \n","1084    [sinner, da, urlo, jannik, sinner, esordisce, con, una, roboante, vittoria, per, contro, hubert, hurkacz, vendica, così, la, sconfitta, nella, finale, di, miami, giovedì, sfiderà, medvedev, matteo, sei, un, idolo, il, suo, messaggio, fine, partita, per, berrettini]\n","1087                                                                                                                                                                                                                                         [matteo, sei, un, idolo, bravissimo]\n","1088                                                                                                                                                                                                       [bellissimo, pensiero, di, per, gli, infortunati, matteo, e, stefanos]\n","1089                                                                                                                                                                                                                                                                     [torino]\n","1090                                                                                                                                                                                                                                    [sinner, non, molla, un, cazzo, pazzesco]\n","Name: ltoken, Length: 311, dtype: object"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"llZq_AUED78d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637672197474,"user_tz":-60,"elapsed":274,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"12fb3c07-74ac-4402-a95a-54cf1a7c3a95"},"source":["number = 3\n","print(f'comment     : {raw_text.to_list()[number]}')\n","print(f'token       : {df_label.token.to_list()[number]}')\n","print(f'ltoken      : {df_label.ltoken.to_list()[number]}')\n","\n","print(df_label.isna().sum())\n","\n","len_target = 1\n","field_name ='ltoken' \n","\n","counter = df_label[df_label[field_name].str.len() < len_target ][field_name].count()\n","print(f'{field_name} with len < {len_target}: {counter}/{len(df_label)}')\n","df_label = df_label[df_label['ltoken'].str.len() > 0]\n","\n","counter = df_label[df_label[field_name].str.len() < len_target ][field_name].count()\n","print(f'{field_name} with len < {len_target}: {counter}/{len(df_label)}')\n","df_label.isna().sum()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["comment     : Due su tre sul veloce, , è un dio. Solo lo può fermare.\n","token       : ['due', 'su', 'tre', 'sul', 'veloce', 'è', 'un', 'dio', 'solo', 'lo', 'può', 'fermare']\n","ltoken      : ['due', 'su', 'tre', 'sul', 'veloce', 'è', 'un', 'dio', 'solo', 'lo', 'può', 'fermare']\n","id                                    0\n","user                                  0\n","date                                  0\n","text                                  0\n","favorite_count                        0\n","hashtags                              0\n","location                            140\n","retweet                               0\n","retweet_count                         0\n","followers_count                       0\n","in_reply_to_status_id               294\n","user_mentions                         0\n","date_norm                             0\n","time_zone                             0\n","text_nonl                             0\n","text_nonl_hash                        0\n","text_nonl_hash_men                    0\n","text_nonl_hash_men_http               0\n","text_nonl_hash_men_http_num           0\n","text_nonl_hash_men_http_num_simb      0\n","text_lang                             0\n","text_lan_code                         0\n","lang_confidence                       0\n","prediction_reliable                   0\n","Medvedev                              0\n","Zverev                                0\n","Berrettini                            0\n","Hurkacz                               0\n","Sinner                                0\n","Djokovic                              0\n","Tsitsipas                             0\n","Rublev                                0\n","Ruud                                  0\n","Norrie                                0\n","ATP_Finals                            0\n","topic                                 0\n","sentiment                             0\n","token                                 0\n","ltoken                                0\n","dtype: int64\n","ltoken with len < 1: 0/311\n","ltoken with len < 1: 0/311\n"]},{"output_type":"execute_result","data":{"text/plain":["id                                    0\n","user                                  0\n","date                                  0\n","text                                  0\n","favorite_count                        0\n","hashtags                              0\n","location                            140\n","retweet                               0\n","retweet_count                         0\n","followers_count                       0\n","in_reply_to_status_id               294\n","user_mentions                         0\n","date_norm                             0\n","time_zone                             0\n","text_nonl                             0\n","text_nonl_hash                        0\n","text_nonl_hash_men                    0\n","text_nonl_hash_men_http               0\n","text_nonl_hash_men_http_num           0\n","text_nonl_hash_men_http_num_simb      0\n","text_lang                             0\n","text_lan_code                         0\n","lang_confidence                       0\n","prediction_reliable                   0\n","Medvedev                              0\n","Zverev                                0\n","Berrettini                            0\n","Hurkacz                               0\n","Sinner                                0\n","Djokovic                              0\n","Tsitsipas                             0\n","Rublev                                0\n","Ruud                                  0\n","Norrie                                0\n","ATP_Finals                            0\n","topic                                 0\n","sentiment                             0\n","token                                 0\n","ltoken                                0\n","dtype: int64"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"dItqZS9DJkVU"},"source":["\n","bigram  = Phrases(df_label.ltoken, min_count=5, threshold=0.2, common_terms=connectors) #gensim 3, ad esempio \"and\" \n","df_label['bigrams_afternostop'] = df_label.ltoken.apply(lambda row: bigram[row])\n","\n","ngram   = Phrases(df_label.bigrams_afternostop, min_count=5, threshold=0.2, common_terms=connectors) # gensim 3\n","df_label['ngrams_afternostop'] = df_label.bigrams_afternostop.apply(lambda row: ngram[row])\n","\n","# df_label.bigrams_afternostop = df_label.bigrams_afternostop.apply(lambda bigr: [item for item in bigr if item not in stop])\n","df_label.ngrams_afternostop = df_label.ngrams_afternostop.apply(lambda ngr: [item for item in ngr if item not in stop])\n","\n","# bigram  = Phrases(df_label.nostopwords, min_count=20, threshold=0.2, common_terms=connectors) #gensim 3, ad esempio \"and\" \n","# df_label['bigrams_beforenostop'] = df_label.nostopwords.apply(lambda row: bigram[row])\n","\n","# ngram   = Phrases(df_label.bigrams_beforenostop, min_count=20, threshold=0.2, common_terms=connectors) # gensim 3\n","# df_label['ngrams_beforenostop'] = df_label.bigrams_beforenostop.apply(lambda row: ngram[row])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AezIVSZzKkN1"},"source":["\n","df_label['bigrams_afternostop_sent'] = df_label.bigrams_afternostop.apply(lambda row: ' '.join(row))\n","df_label['ngrams_afternostop_sent'] = df_label.ngrams_afternostop.apply(lambda row: ' '.join(row))\n","\n","# df_label['bigrams_beforenostop_sent'] = df_label.bigrams_beforenostop.apply(lambda row: ' '.join(row))\n","# df_label['ngrams_beforenostop_sent'] = df_label.ngrams_beforenostop.apply(lambda row: ' '.join(row))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Ku8RhMvSx2u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637672248370,"user_tz":-60,"elapsed":274,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"7b755a6c-b759-4607-8e61-b8dad38042f5"},"source":["\n","# df_label.bigrams_afternostop_sent = df_label.bigrams_afternostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","# df_label.bigrams_beforenostop_sent = df_label.bigrams_beforenostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","# df_label.ngrams_afternostop_sent = df_label.ngrams_afternostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","# df_label.ngrams_beforenostop_sent = df_label.ngrams_beforenostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","\n","print(len(df_label))\n","df_label = df_label[~(df_label.bigrams_afternostop_sent.str.len() == 0)]\n","# df_label = df_label[~(df_label.bigrams_beforenostop_sent.str.len() == 0)]\n","df_label = df_label[~(df_label.ngrams_afternostop_sent.str.len() == 0)]\n","# df_label = df_label[~(df_label.ngrams_beforenostop_sent.str.len() == 0)]\n","print(len(df_label))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["311\n","311\n"]}]},{"cell_type":"code","metadata":{"id":"yaVoykP4ENSz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637672302238,"user_tz":-60,"elapsed":289,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"b1338ef6-636f-4d39-b807-733c0cb654b8"},"source":["\n","\n","# print(df_label.isna().sum())\n","len_target = 1\n","for field_name in ['token', 'ltoken'\n","              ,'bigrams_afternostop_sent' \n","              # ,'bigrams_beforenostop_sent'\n","              ,'ngrams_afternostop_sent'  \n","              # ,'ngrams_beforenostop_sent'\n","              ]: \n","  counter = df_label[df_label[field_name].str.len() < len_target][field_name].count()\n","  print(f'{field_name} with len < {len_target}: {counter}')\n","\n","n = 10\n","print(f'raw_text[{n}] : {raw_text.to_list()[n]}')\n","\n","print(f'df_label.bigrams_afternostop_sent[{n}] : {df_label.bigrams_afternostop_sent.to_list()[n]}')\n","# print(f'df_label.bigrams_beforenostop_sent[{n}]: {df_label.bigrams_beforenostop_sent.to_list()[n]}')\n","print(f'df_label.ngrams_afternostop_sent[{n}]  : {df_label.ngrams_afternostop_sent.to_list()[n]}')\n","# print(f'df_label.ngrams_beforenostop_sent[{n}] : {df_label.ngrams_beforenostop_sent.to_list()[n]}')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["token with len < 1: 0\n","ltoken with len < 1: 0\n","bigrams_afternostop_sent with len < 1: 0\n","ngrams_afternostop_sent with len < 1: 0\n","raw_text[10] : vince il secondo set su È già capolavoro ragazzo! \n","df_label.bigrams_afternostop_sent[10] : vince il_secondo set su è già capolavoro ragazzo\n","df_label.ngrams_afternostop_sent[10]  : vince il_secondo_set su è già capolavoro ragazzo\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0cZA5cM4SDF","executionInfo":{"status":"ok","timestamp":1637672653318,"user_tz":-60,"elapsed":305,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"12923862-b3a1-48ab-fc8e-781f8c24f842"},"source":["df_label_saving = df_label.copy()\n","\n","df_label_saving['cleaned_text'] = df_label_saving['text_nonl_hash_men_http_num']\n","\n","df_label_saving = df_label_saving.loc[:, ['id', 'user', 'date', 'text', 'favorite_count', 'hashtags', 'location',\n","       'retweet', 'retweet_count', 'followers_count', 'in_reply_to_status_id',\n","       'user_mentions', 'date_norm', 'time_zone', 'cleaned_text', 'lang_confidence', 'prediction_reliable',\n","       'Medvedev', 'Zverev', 'Berrettini', 'Hurkacz', 'Sinner', 'Djokovic',\n","       'Tsitsipas', 'Rublev', 'Ruud', 'Norrie', 'ATP_Finals', 'topic',\n","       'token', 'ltoken', 'bigrams_afternostop',\n","       'ngrams_afternostop', 'bigrams_afternostop_sent',\n","       'ngrams_afternostop_sent', 'sentiment']]\n","df_label_saving.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['id', 'user', 'date', 'text', 'favorite_count', 'hashtags', 'location',\n","       'retweet', 'retweet_count', 'followers_count', 'in_reply_to_status_id',\n","       'user_mentions', 'date_norm', 'time_zone', 'cleaned_text',\n","       'lang_confidence', 'prediction_reliable', 'Medvedev', 'Zverev',\n","       'Berrettini', 'Hurkacz', 'Sinner', 'Djokovic', 'Tsitsipas', 'Rublev',\n","       'Ruud', 'Norrie', 'ATP_Finals', 'topic', 'token', 'ltoken',\n","       'bigrams_afternostop', 'ngrams_afternostop', 'bigrams_afternostop_sent',\n","       'ngrams_afternostop_sent', 'sentiment'],\n","      dtype='object')"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"KcfSpnliM0Dt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637672689308,"user_tz":-60,"elapsed":3,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"5a73b3d3-0b7a-4f53-a0b3-5c6f0974c732"},"source":["saving_file_name = f'{st_tone_root_dir}dflabaled_ready4_bow.csv'\n","df_label_saving.to_csv(saving_file_name, index=False, encoding='utf-8', sep =',' )\n","df_label_saving.isna().sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id                            0\n","user                          0\n","date                          0\n","text                          0\n","favorite_count                0\n","hashtags                      0\n","location                    140\n","retweet                       0\n","retweet_count                 0\n","followers_count               0\n","in_reply_to_status_id       294\n","user_mentions                 0\n","date_norm                     0\n","time_zone                     0\n","cleaned_text                  0\n","lang_confidence               0\n","prediction_reliable           0\n","Medvedev                      0\n","Zverev                        0\n","Berrettini                    0\n","Hurkacz                       0\n","Sinner                        0\n","Djokovic                      0\n","Tsitsipas                     0\n","Rublev                        0\n","Ruud                          0\n","Norrie                        0\n","ATP_Finals                    0\n","topic                         0\n","token                         0\n","ltoken                        0\n","bigrams_afternostop           0\n","ngrams_afternostop            0\n","bigrams_afternostop_sent      0\n","ngrams_afternostop_sent       0\n","sentiment                     0\n","dtype: int64"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"avG5NFW_PaG-"},"source":["## 6.3 BOW"]},{"cell_type":"markdown","metadata":{"id":"bzXO8V4FoZOG"},"source":["### 6.3.1 Fit tennis dictionary and save it"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-IKvGy2nzVZ","executionInfo":{"status":"ok","timestamp":1637672708058,"user_tz":-60,"elapsed":980,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"f77fdbed-8520-444c-98e9-5cc428a1a70c"},"source":["opening_file_name = f'{sentiment_root_dir}ngrams_ourdataset_dataframe.csv'\n","df_open_full = pd.read_csv(opening_file_name, encoding='utf-8', sep =',' )\n","df_open_full.isna().sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["id                           0\n","user                         0\n","date                         0\n","text                         0\n","text_cleaned                 0\n","text_lan_code                0\n","lang_confidence              0\n","prediction_reliable          0\n","topic                        0\n","bigrams_afternostop_sent     0\n","bigrams_beforenostop_sent    0\n","ngrams_afternostop_sent      0\n","ngrams_beforenostop_sent     0\n","dtype: int64"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"9Vr0RCYjoYOf"},"source":["import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","import pickle\n","\n","df_full = df_open_full.copy()\n","\n","vectorizer = CountVectorizer(ngram_range=(1, 1), max_features=1000)\n","# vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=1000)\n","X = vectorizer.fit(df_full['ngrams_afternostop_sent'].to_list())\n","feature_names = vectorizer.get_feature_names()\n","# print(feature_names)\n","\n","model_filename = f\"{models_root_dir}our_bow_dict_model.pkl\"\n","with open(model_filename, 'wb') as file:\n","    pickle.dump(vectorizer, file)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P0dA7aIspDMN","executionInfo":{"status":"ok","timestamp":1637670457057,"user_tz":-60,"elapsed":258,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"21ef7a72-3003-4f04-83a0-124acd0835fc"},"source":["print(X)\n","print(feature_names[0:100])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CountVectorizer(max_features=1000)\n","['able', 'absolutely', 'absolutely_pathetic_schedule_tournament', 'account', 'ace', 'action', 'actually', 'add', 'age_player_atp_final', 'agree', 'ahead', 'ahead_debut_evening_ha', 'al', 'alert_new_high_roller', 'alex_zverev', 'alexander', 'alexander_second_defeat_medvedev', 'alexander_zverev', 'allez_amp_champion_second', 'almost', 'already', 'also', 'alternate', 'always', 'always_applauding_opponent_hit', 'amazing', 'amp', 'amp_defeat_ram_salisbury', 'amp_grande_ibra_uvek', 'amp_stay_unblemished', 'amp_two_time_champion', 'ana', 'andre_agassi_alexander_zverev', 'andrei_rublev', 'andrey', 'andrey_rublev', 'andrey_rublev_beat_stefanos', 'anime_murder_ok_john', 'another', 'answer', 'anyone', 'anyone_offends_know_far', 'anything', 'anyway', 'apart_djokovic_djokovic_least', 'around', 'ask', 'asked', 'atp', 'atp_final', 'atp_final_defending_champ', 'atp_final_sunday_pm', 'atp_tour', 'atp_tour_season', 'atp_world_tour_final', 'attack', 'australian_open_roland_garros', 'awaits', 'away', 'baby', 'back', 'back_back_final_russian', 'back_title', 'backhand', 'bad', 'bad_gift_world', 'ball', 'banter', 'based', 'battle', 'beat', 'beat_djokovic_amp_medvedev', 'beat_hurkacz_sinner_need', 'beat_medvedev_hurkacz_beat', 'beaten', 'beating', 'beautiful', 'become', 'become_first_alternate_win', 'begin', 'behind', 'behind_baseline_incredible_point', 'belgrade_u_open_f', 'believe', 'berrettini', 'best', 'best_best_last_decade', 'bet', 'bet_posted_bet_ha', 'better', 'biden', 'big', 'bit', 'bit_pre_match_friendly', 'blocked', 'book', 'boy', 'bravissimo_wa_awarded_year', 'bravo_jannik_turin_bid', 'break']\n"]}]},{"cell_type":"markdown","metadata":{"id":"-onS0Q7NNAPh"},"source":["### 6.3.2 Labelled csv\n"]},{"cell_type":"code","metadata":{"id":"UGQ3bcvQNgA2","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1637672751137,"user_tz":-60,"elapsed":276,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"a5100da2-2b3e-46eb-f54a-40aac488ff47"},"source":["df_open_label = pd.read_csv(f'{st_tone_root_dir}dflabaled_ready4_bow.csv', encoding='utf-8', sep =',', header=0 )\n","\n","# df.bigrams_afternostop_sent = df.bigrams_afternostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","# df.bigrams_beforenostop_sent = df.bigrams_beforenostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","# df.ngrams_afternostop_sent = df.ngrams_afternostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","# df.ngrams_beforenostop_sent = df.ngrams_beforenostop_sent.str.replace('[^\\w\\s]',' ').str.replace('\\s+', ' ', regex=True).str.strip()\n","\n","# print(len(df_open))\n","# df_open = df_open[~(df_open.bigrams_afternostop_sent.str.len() == 0)]\n","# df_open = df_open[~(df_open.bigrams_beforenostop_sent.str.len() == 0)]\n","# df_open = df_open[~(df_open.ngrams_afternostop_sent.str.len() == 0)]\n","# df_open = df_open[~(df_open.ngrams_beforenostop_sent.str.len() == 0)]\n","# print(len(df_open))\n","\n","print(df_open_label.isna().sum())\n","df_open_label.head(2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["id                            0\n","user                          0\n","date                          0\n","text                          0\n","favorite_count                0\n","hashtags                      0\n","location                    140\n","retweet                       0\n","retweet_count                 0\n","followers_count               0\n","in_reply_to_status_id       294\n","user_mentions                 0\n","date_norm                     0\n","time_zone                     0\n","cleaned_text                  0\n","lang_confidence               0\n","prediction_reliable           0\n","Medvedev                      0\n","Zverev                        0\n","Berrettini                    0\n","Hurkacz                       0\n","Sinner                        0\n","Djokovic                      0\n","Tsitsipas                     0\n","Rublev                        0\n","Ruud                          0\n","Norrie                        0\n","ATP_Finals                    0\n","topic                         0\n","token                         0\n","ltoken                        0\n","bigrams_afternostop           0\n","ngrams_afternostop            0\n","bigrams_afternostop_sent      0\n","ngrams_afternostop_sent       0\n","sentiment                     0\n","dtype: int64\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>user</th>\n","      <th>date</th>\n","      <th>text</th>\n","      <th>favorite_count</th>\n","      <th>hashtags</th>\n","      <th>location</th>\n","      <th>retweet</th>\n","      <th>retweet_count</th>\n","      <th>followers_count</th>\n","      <th>in_reply_to_status_id</th>\n","      <th>user_mentions</th>\n","      <th>date_norm</th>\n","      <th>time_zone</th>\n","      <th>cleaned_text</th>\n","      <th>lang_confidence</th>\n","      <th>prediction_reliable</th>\n","      <th>Medvedev</th>\n","      <th>Zverev</th>\n","      <th>Berrettini</th>\n","      <th>Hurkacz</th>\n","      <th>Sinner</th>\n","      <th>Djokovic</th>\n","      <th>Tsitsipas</th>\n","      <th>Rublev</th>\n","      <th>Ruud</th>\n","      <th>Norrie</th>\n","      <th>ATP_Finals</th>\n","      <th>topic</th>\n","      <th>token</th>\n","      <th>ltoken</th>\n","      <th>bigrams_afternostop</th>\n","      <th>ngrams_afternostop</th>\n","      <th>bigrams_afternostop_sent</th>\n","      <th>ngrams_afternostop_sent</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1460007859798827012</td>\n","      <td>illeaoiano</td>\n","      <td>Sun Nov 14 22:12:54 +0000 2021</td>\n","      <td>zverev mi è sempre piaciuto, dopo questo gesto ancora di più https://t.co/9ElOVRFyVM</td>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>NaN</td>\n","      <td>False</td>\n","      <td>13</td>\n","      <td>53</td>\n","      <td>NaN</td>\n","      <td>['acm95fede']</td>\n","      <td>2021-11-14 22:12:54</td>\n","      <td>z+0000</td>\n","      <td>zverev mi è sempre piaciuto, dopo questo gesto ancora di più</td>\n","      <td>98.0</td>\n","      <td>True</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>['zverev', 'mi', 'è', 'sempre', 'piaciuto', 'dopo', 'questo', 'gesto', 'ancora', 'di', 'più']</td>\n","      <td>['zverev', 'mi', 'è', 'sempre', 'piaciuto', 'dopo', 'questo', 'gesto', 'ancora', 'di', 'più']</td>\n","      <td>['zverev_mi', 'è_sempre', 'piaciuto_dopo', 'questo_gesto', 'ancora_di', 'più']</td>\n","      <td>['zverev_mi_è_sempre', 'piaciuto_dopo_questo_gesto', 'ancora_di_più']</td>\n","      <td>zverev_mi è_sempre piaciuto_dopo questo_gesto ancora_di più</td>\n","      <td>zverev_mi_è_sempre piaciuto_dopo_questo_gesto ancora_di_più</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1460007472245137412</td>\n","      <td>alessia__Z</td>\n","      <td>Sun Nov 14 22:11:21 +0000 2021</td>\n","      <td>zverev mi è sempre piaciuto, dopo questo gesto ancora di più https://t.co/9ElOVRFyVM</td>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>Milanello</td>\n","      <td>False</td>\n","      <td>13</td>\n","      <td>1505</td>\n","      <td>NaN</td>\n","      <td>['acm95fede']</td>\n","      <td>2021-11-14 22:11:21</td>\n","      <td>z+0000</td>\n","      <td>zverev mi è sempre piaciuto, dopo questo gesto ancora di più</td>\n","      <td>98.0</td>\n","      <td>True</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>['zverev', 'mi', 'è', 'sempre', 'piaciuto', 'dopo', 'questo', 'gesto', 'ancora', 'di', 'più']</td>\n","      <td>['zverev', 'mi', 'è', 'sempre', 'piaciuto', 'dopo', 'questo', 'gesto', 'ancora', 'di', 'più']</td>\n","      <td>['zverev_mi', 'è_sempre', 'piaciuto_dopo', 'questo_gesto', 'ancora_di', 'più']</td>\n","      <td>['zverev_mi_è_sempre', 'piaciuto_dopo_questo_gesto', 'ancora_di_più']</td>\n","      <td>zverev_mi è_sempre piaciuto_dopo questo_gesto ancora_di più</td>\n","      <td>zverev_mi_è_sempre piaciuto_dopo_questo_gesto ancora_di_più</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                    id  ... sentiment\n","0  1460007859798827012  ...         1\n","1  1460007472245137412  ...         1\n","\n","[2 rows x 36 columns]"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_myIwXezxPS8","executionInfo":{"status":"ok","timestamp":1637670565985,"user_tz":-60,"elapsed":286,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"15377636-fb45-4925-ccc1-81510fe52fdb"},"source":["df_open_label.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1092, 37)"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"w58Xsm58Pfok"},"source":["import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","\n","df = df_open_label.copy()\n","# number_of_row = 1000\n","# # number_of_row = len(df['y'] == 1])\n","# df = df[df['y'] == 1].sample(number_of_row, random_state= 123).append(df[df['y'] == 0].sample(number_of_row, random_state= 123))\n","# print(f'reduced df len: {len(df)}')\n","# # 'comment', 'rating', 'bigrams_afternostop_sent',\n","# #        'bigrams_beforenostop_sent', 'ngrams_afternostop_sent',\n","# #        'ngrams_beforenostop_sent', 'y'\n","\n","# choosen_column_2vec = 'ngrams_afternostop_sent'\n","\n","# vectorizer = CountVectorizer(ngram_range=(1, 1), max_features=1000)\n","# # vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=1000)\n","\n","# model_filename = f\"{models_root_dir}our_bow_dict_model.pkl\"\n","# with open(model_filename, 'rb') as file:\n","#     vectorizer = pickle.load(file)\n","\n","X = vectorizer.transform(df['ngrams_afternostop_sent'].to_list())\n","# # feature_names = vectorizer.get_feature_names()\n","# # print(feature_names)\n","\n","X = X.toarray()\n","X = np.array(X)\n","y = np.array(df['sentiment'].to_list())\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.1, random_state=42)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VTLDlWeGbVDQ"},"source":["all_ngrams = []\n","for ngram_list in df.ngrams_afternostop_sent.to_list():\n","  all_ngrams.extend(ngram_list.split())\n","\n","from collections import Counter\n","counter = Counter(all_ngrams)\n","counter.most_common(100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JXmblkksyWfj"},"source":["feature_names = vectorizer.get_feature_names()\n","feature_names[:100]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"igbKAnS0VhMm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637672846407,"user_tz":-60,"elapsed":640,"user":{"displayName":"Antonello Scarcella","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh6taESDBfU-YIXZWVLHasC6VgtQVDfGxALx5JntA=s64","userId":"06718551243875026944"}},"outputId":"a9d3061c-e9f4-4141-9a96-6df1630cdd81"},"source":["from tqdm import tqdm\n","from sklearn import tree\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import StratifiedKFold, cross_val_score\n","from sklearn.metrics import accuracy_score, recall_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report\n","import pickle\n","\n","#################################################################################à\n","tree_model = tree.DecisionTreeClassifier(max_leaf_nodes=10, max_depth=5)\n","#################################################################################à\n","tree_model.fit(x_train, y_train)\n","\n","# Save to file in the current working directory\n","model_filename = f\"{models_root_dir}our_bow_dict_model.pkl\"\n","with open(model_filename, 'wb') as file:\n","    pickle.dump(tree_model, file)\n","# Load from file\n","with open(model_filename, 'rb') as file:\n","    tree_model = pickle.load(file)\n","\n","predicted = tree_model.predict(x_test)\n","print(f\"\"\"tree_model: \n","{classification_report(y_test, predicted)}\"\"\")\n","\n","#################################################################################à\n","logit_model = LogisticRegression(class_weight=None)\n","#################################################################################à\n","logit_model.fit(x_train, y_train)\n","# Save to file in the current working directory\n","model_filename = f\"{models_root_dir}basic_logit_model.pkl\"\n","with open(model_filename, 'wb') as file:\n","    pickle.dump(logit_model, file)\n","# Load from file\n","with open(model_filename, 'rb') as file:\n","    logit_model = pickle.load(file)\n","\n","predicted = logit_model.predict(x_test)\n","print(f\"\"\"logit_model: \n","{classification_report(y_test, predicted)}\"\"\")\n","\n","#################################################################################à\n","random_model = RandomForestClassifier()\n","#################################################################################à\n","random_model.fit(x_train, y_train)\n","# Save to file in the current working directory\n","model_filename = f\"{models_root_dir}basic_random_model.pkl\"\n","with open(model_filename, 'wb') as file:\n","    pickle.dump(random_model, file)\n","# Load from file\n","with open(model_filename, 'rb') as file:\n","    random_model = pickle.load(file)\n","\n","predicted = random_model.predict(x_test)\n","print(f\"\"\"random_model: \n","{classification_report(y_test, predicted)}\"\"\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tree_model: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         3\n","           1       0.90      0.97      0.93        29\n","\n","    accuracy                           0.88        32\n","   macro avg       0.45      0.48      0.47        32\n","weighted avg       0.82      0.88      0.85        32\n","\n","logit_model: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         3\n","           1       0.91      1.00      0.95        29\n","\n","    accuracy                           0.91        32\n","   macro avg       0.45      0.50      0.48        32\n","weighted avg       0.82      0.91      0.86        32\n","\n","random_model: \n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         3\n","           1       0.90      0.97      0.93        29\n","\n","    accuracy                           0.88        32\n","   macro avg       0.45      0.48      0.47        32\n","weighted avg       0.82      0.88      0.85        32\n","\n"]}]},{"cell_type":"code","metadata":{"id":"etnN_JA2Shs-"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XcNbgQCDShs_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z7-bSqpxyl3X"},"source":["# 7. Word embeddings\n","TONE'"]},{"cell_type":"code","metadata":{"id":"jpxFJs7uytJe"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0lfMGMxdypst"},"source":["# 8. Lime"]},{"cell_type":"code","metadata":{"id":"eOBsslToysP2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lyhEC_7ShQUW"},"source":["# 9. SocialNetwork Analisys"]}]}